{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorial Word Representations\n",
    "\n",
    "## Background\n",
    "Representing words as dense vectors over a finite-dimensional space was one of the recent breakthroughs in Natural Language Processing. Vectorial representations allow space-efficient, informationally rich storage of words that adequately captures their semantic content and enables numerical computation on them. Word vectors are the standard input representation for machine learning architectures for language processing. Even though new methods for constructing such representations emerge frequently, the original set of published papers remain a de facto point of reference as well as a good starting point. For this assignment, you will be asked to implement a small-scale variant of one such paper, namely [Global Word Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf) (\"the GloVe paper\").\n",
    "\n",
    "Much of the code and data pre-processing has already been done for you. Additionally, notes on the paper will appear throughout the notebook to guide you along the code. It is, however, important to read and understand the paper, its terminology and the theory behind it before attempting to go through with the assignment. Some of the tasks will also require addressing the paper directly.\n",
    "\n",
    "**-------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "There are 2 types of tasks in this assignment: \n",
    "- coding tasks --- 10 tasks worth 1 point each --- asking you to write code following specifications provided; make sure to <ins>show the code to your teacher after completing every coding task</ins>\n",
    "- interpretation questions --- 5 questions worth 1 point each --- asking you to interpret the data or the results of the model\n",
    "\n",
    "You are greatly encouraged to add comments to your code describing what particular lines of code do (in general, a great habit to have in your coding life), as well as self-check regularly by printing your tensors and their shapes making sure they look adequate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics\n",
    "\n",
    "The paper's proposed model, GloVe, aims to densely represent words in a way that captures the global corpus statistics. \n",
    "\n",
    "The construction it encodes is the word __co-occurrence matrix__. A co-occurrence matrix is a simplistic data structure that counts the number of times each word has appeared within the context of every other word. The definition of a context varies; usually, context is implied to be a fixed-length span (that may or may not be allowed to escape sentence boundaries) around a word. \n",
    "\n",
    "For instance, in the sentence below and for a context length of 2, the word <span style=\"color:pink\">__Earth__</span> occurs in the context of <span style=\"color:lightgreen\">made</span> (1), <span style=\"color:lightgreen\">on</span> (1), <span style=\"color:lightgreen\">as</span> (1), <span style=\"color:lightgreen\">an</span> (1).\n",
    "\n",
    "> \"He struck most of the friends he had <span style=\"color:lightgreen\">made on</span> <span style=\"color:pink\">__Earth__</span> <span style=\"color:lightgreen\">as an</span> eccentric\"\n",
    "\n",
    "Similarly, the word <span style=\"color:pink\">__friends__</span> occurs in the context of <span style=\"color:lightgreen\">of</span> (1), <span style=\"color:lightgreen\">the</span> (1), <span style=\"color:lightgreen\">he</span> (1), <span style=\"color:lightgreen\">had</span> (1).\n",
    "\n",
    "> \"He struck most <span style=\"color:lightgreen\">of the</span> <span style=\"color:pink\">__friends__</span> <span style=\"color:lightgreen\">he had</span> made on Earth as an eccentric\"\n",
    "\n",
    "An alternative definition of a context would be, for instance, the variable-length windows spanned by a full sentence.\n",
    "\n",
    "Contexts may be summed across sentences or entire corpora; the summed context of <span style=\"color:pink\">he</span> in the example sentence is: <span style=\"color:lightgreen\">struck</span> (1), <span style=\"color:lightgreen\">most</span> (1), <span style=\"color:lightgreen\">the</span> (1), <span style=\"color:lightgreen\">friends</span> (1), <span style=\"color:lightgreen\">had</span> (1), <span style=\"color:lightgreen\">made</span> (1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this assignment, we have prepared a co-occurrence matrix over a minimally processed version of the Harry Potter books.\n",
    "\n",
    "(A few interpretation tasks in this assignment presuppose some minimal level of familiarity with the Harry Potter books/films. If no one in your group is familiar with Harry Potter, please talk to your teacher)\n",
    "\n",
    "The pickle file contains three items:\n",
    "1. `vocab`: a dictionary mapping words to unique ids, containing $N$ unique words\n",
    "2. `contexts`: a dictionary mapping words to their contexts, where contexts are themselves dicts from words to integers that show the number of co-occurrences between these words.\n",
    "    E.g. `{\"portrait\": {\"harry\": 103, \"said\": 97, ...}, ...}` meaning that the word \"harry\" has appeared in the context of the word \"portrait\" 103 times, etc.\n",
    "3. `X`: a torch LongTensor ${X}$ of size $N \\times N$, where ${X}[i,j]$ denotes the number of times the word with id $j$ has appeared in the context of the word with id $i$\n",
    "\n",
    "Extremely common or uncommon words (i.e. words with too few or too many global occurrences) have been filtered out for practical reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch import FloatTensor, LongTensor\n",
    "from typing import Dict, Callable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359\n"
     ]
    }
   ],
   "source": [
    "with open(\"output.p\", \"rb\") as f:\n",
    "    vocab, contexts, X = pickle.load(f)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the summed context of the word 'portrait'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harry', 103),\n",
       " ('said', 97),\n",
       " ('hole', 84),\n",
       " ('ron', 49),\n",
       " ('hermione', 46),\n",
       " ('room', 41),\n",
       " ('t', 40),\n",
       " ('fat', 39),\n",
       " ('lady', 39),\n",
       " ('common', 30),\n",
       " ('dumbledore', 26),\n",
       " ('phineas', 24),\n",
       " ('climbed', 22),\n",
       " ('just', 19),\n",
       " ('swung', 17),\n",
       " ('sirius', 17),\n",
       " ('professor', 17),\n",
       " ('time', 16),\n",
       " ('voice', 15),\n",
       " ('open', 15),\n",
       " ('got', 15),\n",
       " ('nigellus', 15),\n",
       " ('reached', 14),\n",
       " ('like', 14),\n",
       " ('came', 14),\n",
       " ('little', 14),\n",
       " ('gryffindor', 13),\n",
       " ('turned', 13),\n",
       " ('forward', 12),\n",
       " ('don', 12),\n",
       " ('long', 12),\n",
       " ('place', 12),\n",
       " ('wall', 11),\n",
       " ('neville', 11),\n",
       " ('black', 11),\n",
       " ('going', 11),\n",
       " ('snape', 11),\n",
       " ('hall', 11),\n",
       " ('mcgonagall', 11),\n",
       " ('corridor', 10),\n",
       " ('walked', 10),\n",
       " ('away', 10),\n",
       " ('ve', 10),\n",
       " ('way', 10),\n",
       " ('visit', 10),\n",
       " ('good', 10),\n",
       " ('did', 10),\n",
       " ('look', 10),\n",
       " ('password', 9),\n",
       " ('moment', 9),\n",
       " ('know', 9),\n",
       " ('sir', 9),\n",
       " ('opened', 9),\n",
       " ('face', 9),\n",
       " ('heard', 9),\n",
       " ('come', 8),\n",
       " ('gone', 8),\n",
       " ('asked', 8),\n",
       " ('let', 8),\n",
       " ('really', 8),\n",
       " ('entrance', 8),\n",
       " ('cadogan', 8),\n",
       " ('mother', 8),\n",
       " ('door', 8),\n",
       " ('pushed', 7),\n",
       " ('inside', 7),\n",
       " ('cloak', 7),\n",
       " ('looked', 7),\n",
       " ('picture', 7),\n",
       " ('staircase', 7),\n",
       " ('oh', 7),\n",
       " ('tower', 7),\n",
       " ('head', 7),\n",
       " ('ginny', 7),\n",
       " ('thought', 7),\n",
       " ('passed', 7),\n",
       " ('minister', 7),\n",
       " ('fudge', 7),\n",
       " ('scrambled', 6),\n",
       " ('looking', 6),\n",
       " ('bed', 6),\n",
       " ('hagrid', 6),\n",
       " ('himself', 6),\n",
       " ('point', 6),\n",
       " ('house', 6),\n",
       " ('castle', 6),\n",
       " ('tried', 6),\n",
       " ('coming', 6),\n",
       " ('need', 6),\n",
       " ('hurried', 6),\n",
       " ('stood', 6),\n",
       " ('saw', 6),\n",
       " ('people', 6),\n",
       " ('knew', 6),\n",
       " ('frame', 6),\n",
       " ('eyes', 6),\n",
       " ('dean', 6),\n",
       " ('wizard', 6),\n",
       " ('grimmauld', 6),\n",
       " ('headmaster', 6),\n",
       " ('won', 5),\n",
       " ('dress', 5),\n",
       " ('followed', 5),\n",
       " ('running', 5),\n",
       " ('seventh', 5),\n",
       " ('floor', 5),\n",
       " ('thing', 5),\n",
       " ('dormitory', 5),\n",
       " ('stairs', 5),\n",
       " ('pulled', 5),\n",
       " ('went', 5),\n",
       " ('m', 5),\n",
       " ('waiting', 5),\n",
       " ('yelled', 5),\n",
       " ('colin', 5),\n",
       " ('took', 5),\n",
       " ('left', 5),\n",
       " ('gryffindors', 5),\n",
       " ('talking', 5),\n",
       " ('doors', 5),\n",
       " ('felt', 5),\n",
       " ('office', 5),\n",
       " ('fred', 5),\n",
       " ('great', 5),\n",
       " ('set', 5),\n",
       " ('gave', 5),\n",
       " ('approached', 5),\n",
       " ('downstairs', 5),\n",
       " ('parchment', 5),\n",
       " ('dinner', 5),\n",
       " ('silver', 5),\n",
       " ('walk', 5),\n",
       " ('prime', 5),\n",
       " ('end', 4),\n",
       " ('hung', 4),\n",
       " ('woman', 4),\n",
       " ('pink', 4),\n",
       " ('percy', 4),\n",
       " ('reveal', 4),\n",
       " ('chair', 4),\n",
       " ('couldn', 4),\n",
       " ('care', 4),\n",
       " ('didn', 4),\n",
       " ('herself', 4),\n",
       " ('painting', 4),\n",
       " ('mind', 4),\n",
       " ('entered', 4),\n",
       " ('crept', 4),\n",
       " ('appeared', 4),\n",
       " ('stand', 4),\n",
       " ('short', 4),\n",
       " ('crowd', 4),\n",
       " ('spiral', 4),\n",
       " ('deserted', 4),\n",
       " ('caught', 4),\n",
       " ('began', 4),\n",
       " ('waited', 4),\n",
       " ('climbing', 4),\n",
       " ('large', 4),\n",
       " ('called', 4),\n",
       " ('boys', 4),\n",
       " ('past', 4),\n",
       " ('headed', 4),\n",
       " ('nearly', 4),\n",
       " ('years', 4),\n",
       " ('minutes', 4),\n",
       " ('closed', 4),\n",
       " ('later', 4),\n",
       " ('canvas', 4),\n",
       " ('able', 4),\n",
       " ('taken', 4),\n",
       " ('half', 4),\n",
       " ('simply', 4),\n",
       " ('ask', 4),\n",
       " ('sitting', 4),\n",
       " ('returned', 4),\n",
       " ('george', 4),\n",
       " ('night', 4),\n",
       " ('think', 4),\n",
       " ('lavender', 4),\n",
       " ('tell', 4),\n",
       " ('screaming', 4),\n",
       " ('old', 4),\n",
       " ('doing', 4),\n",
       " ('curtains', 4),\n",
       " ('figures', 4),\n",
       " ('ran', 4),\n",
       " ('odd', 4),\n",
       " ('painted', 4),\n",
       " ('bedroom', 4),\n",
       " ('desk', 4),\n",
       " ('barely', 4),\n",
       " ('silence', 4),\n",
       " ('explanation', 4),\n",
       " ('ugly', 4),\n",
       " ('man', 4),\n",
       " ('bag', 4),\n",
       " ('listen', 3),\n",
       " ('silk', 3),\n",
       " ('needed', 3),\n",
       " ('leg', 3),\n",
       " ('fireplace', 3),\n",
       " ('armchairs', 3),\n",
       " ('spoke', 3),\n",
       " ('believe', 3),\n",
       " ('wanted', 3),\n",
       " ('stop', 3),\n",
       " ('pig', 3),\n",
       " ('snout', 3),\n",
       " ('save', 3),\n",
       " ('packed', 3),\n",
       " ('use', 3),\n",
       " ('stopped', 3),\n",
       " ('managed', 3),\n",
       " ('climb', 3),\n",
       " ('invisibility', 3),\n",
       " ('sorry', 3),\n",
       " ('hurrying', 3),\n",
       " ('fight', 3),\n",
       " ('new', 3),\n",
       " ('impatiently', 3),\n",
       " ('standing', 3),\n",
       " ('leaving', 3),\n",
       " ('creevey', 3),\n",
       " ('lockhart', 3),\n",
       " ('trolls', 3),\n",
       " ('pointing', 3),\n",
       " ('wait', 3),\n",
       " ('gray', 3),\n",
       " ('immediately', 3),\n",
       " ('closing', 3),\n",
       " ('corridors', 3),\n",
       " ('hidden', 3),\n",
       " ('trouble', 3),\n",
       " ('threw', 3),\n",
       " ('right', 3),\n",
       " ('watch', 3),\n",
       " ('d', 3),\n",
       " ('rest', 3),\n",
       " ('students', 3),\n",
       " ('heads', 3),\n",
       " ('vanished', 3),\n",
       " ('crookshanks', 3),\n",
       " ('shut', 3),\n",
       " ('dormitories', 3),\n",
       " ('completely', 3),\n",
       " ('mad', 3),\n",
       " ('shall', 3),\n",
       " ('outside', 3),\n",
       " ('read', 3),\n",
       " ('tiny', 3),\n",
       " ('walls', 3),\n",
       " ('extremely', 3),\n",
       " ('met', 3),\n",
       " ('table', 3),\n",
       " ('grounds', 3),\n",
       " ('corner', 3),\n",
       " ('sight', 3),\n",
       " ('told', 3),\n",
       " ('circular', 3),\n",
       " ('hand', 3),\n",
       " ('silent', 3),\n",
       " ('noise', 3),\n",
       " ('eye', 3),\n",
       " ('admit', 3),\n",
       " ('stay', 3),\n",
       " ('clambered', 3),\n",
       " ('realized', 3),\n",
       " ('mrs', 3),\n",
       " ('taking', 3),\n",
       " ('expression', 3),\n",
       " ('movement', 3),\n",
       " ('hair', 3),\n",
       " ('slightly', 3),\n",
       " ('wearing', 3),\n",
       " ('wand', 3),\n",
       " ('trying', 3),\n",
       " ('dark', 3),\n",
       " ('marching', 3),\n",
       " ('calling', 3),\n",
       " ('introduce', 3),\n",
       " ('announced', 3),\n",
       " ('arrival', 3),\n",
       " ('mentioned', 3),\n",
       " ('romilda', 3),\n",
       " ('vane', 3),\n",
       " ('word', 3),\n",
       " ('sped', 3),\n",
       " ('witches', 3),\n",
       " ('armor', 3),\n",
       " ('steps', 3),\n",
       " ('girl', 3),\n",
       " ('ariana', 3),\n",
       " ('severus', 3),\n",
       " ('bloody', 2),\n",
       " ('control', 2),\n",
       " ('prefects', 2),\n",
       " ('glowing', 2),\n",
       " ('shadows', 2),\n",
       " ('wasn', 2),\n",
       " ('easily', 2),\n",
       " ('angry', 2),\n",
       " ('train', 2),\n",
       " ('tomorrow', 2),\n",
       " ('nighttime', 2),\n",
       " ('shoulders', 2),\n",
       " ('toppled', 2),\n",
       " ('guess', 2),\n",
       " ('stuck', 2),\n",
       " ('clock', 2),\n",
       " ('burst', 2),\n",
       " ('clearly', 2),\n",
       " ('cut', 2),\n",
       " ('arrive', 2),\n",
       " ('arms', 2),\n",
       " ('better', 2),\n",
       " ('camera', 2),\n",
       " ('longbottom', 2),\n",
       " ('held', 2),\n",
       " ('winking', 2),\n",
       " ('shoulder', 2),\n",
       " ('quidditch', 2),\n",
       " ('practice', 2),\n",
       " ('watched', 2),\n",
       " ('board', 2),\n",
       " ('justin', 2),\n",
       " ('usually', 2),\n",
       " ('snow', 2),\n",
       " ('counting', 2),\n",
       " ('distant', 2),\n",
       " ('sounds', 2),\n",
       " ('throwing', 2),\n",
       " ('teachers', 2),\n",
       " ('slid', 2),\n",
       " ('miserable', 2),\n",
       " ('crossed', 2),\n",
       " ('lot', 2),\n",
       " ('marble', 2),\n",
       " ('girls', 2),\n",
       " ('hasn', 2),\n",
       " ('glad', 2),\n",
       " ('weren', 2),\n",
       " ('second', 2),\n",
       " ('work', 2),\n",
       " ('turn', 2),\n",
       " ('feast', 2),\n",
       " ('glancing', 2),\n",
       " ('isn', 2),\n",
       " ('curiously', 2),\n",
       " ('closer', 2),\n",
       " ('torn', 2),\n",
       " ('whisper', 2),\n",
       " ('moving', 2),\n",
       " ('hiding', 2),\n",
       " ('ripped', 2),\n",
       " ('firmly', 2),\n",
       " ('cloaks', 2),\n",
       " ('oak', 2),\n",
       " ('christmas', 2),\n",
       " ('party', 2),\n",
       " ('previous', 2),\n",
       " ('headmasters', 2),\n",
       " ('sat', 2),\n",
       " ('carried', 2),\n",
       " ('staring', 2),\n",
       " ('stared', 2),\n",
       " ('delighted', 2),\n",
       " ('match', 2),\n",
       " ('getting', 2),\n",
       " ('weasley', 2),\n",
       " ('shaking', 2),\n",
       " ('breath', 2),\n",
       " ('em', 2),\n",
       " ('landing', 2),\n",
       " ('laughing', 2),\n",
       " ('bit', 2),\n",
       " ('concealed', 2),\n",
       " ('peeves', 2),\n",
       " ('ears', 2),\n",
       " ('join', 2),\n",
       " ('potter', 2),\n",
       " ('say', 2),\n",
       " ('annoyed', 2),\n",
       " ('laugh', 2),\n",
       " ('year', 2),\n",
       " ('demanded', 2),\n",
       " ('seen', 2),\n",
       " ('friend', 2),\n",
       " ('yell', 2),\n",
       " ('woke', 2),\n",
       " ('shown', 2),\n",
       " ('mood', 2),\n",
       " ('quite', 2),\n",
       " ('life', 2),\n",
       " ('rolling', 2),\n",
       " ('wake', 2),\n",
       " ('led', 2),\n",
       " ('added', 2),\n",
       " ('hear', 2),\n",
       " ('free', 2),\n",
       " ('idea', 2),\n",
       " ('scowled', 2),\n",
       " ('halt', 2),\n",
       " ('correct', 2),\n",
       " ('revealing', 2),\n",
       " ('talk', 2),\n",
       " ('kind', 2),\n",
       " ('light', 2),\n",
       " ('kept', 2),\n",
       " ('allowed', 2),\n",
       " ('sound', 2),\n",
       " ('dead', 2),\n",
       " ('cold', 2),\n",
       " ('covered', 2),\n",
       " ('hastily', 2),\n",
       " ('feet', 2),\n",
       " ('seamus', 2),\n",
       " ('panting', 2),\n",
       " ('view', 2),\n",
       " ('st', 2),\n",
       " ('mungo', 2),\n",
       " ('looks', 2),\n",
       " ('bad', 2),\n",
       " ('clever', 2),\n",
       " ('pointed', 2),\n",
       " ('slytherin', 2),\n",
       " ('longer', 2),\n",
       " ('message', 2),\n",
       " ('traveling', 2),\n",
       " ('study', 2),\n",
       " ('healer', 2),\n",
       " ('sideways', 2),\n",
       " ('queue', 2),\n",
       " ('shining', 2),\n",
       " ('middle', 2),\n",
       " ('amused', 2),\n",
       " ('apparently', 2),\n",
       " ('red', 2),\n",
       " ('forest', 2),\n",
       " ('dawn', 2),\n",
       " ('arguing', 2),\n",
       " ('broken', 2),\n",
       " ('pictures', 2),\n",
       " ('dippet', 2),\n",
       " ('owe', 2),\n",
       " ('hurtled', 2),\n",
       " ('ignoring', 2),\n",
       " ('tonight', 2),\n",
       " ('naturally', 2),\n",
       " ('uncomfortable', 2),\n",
       " ('curly', 2),\n",
       " ('digging', 2),\n",
       " ('ear', 2),\n",
       " ('wish', 2),\n",
       " ('image', 2),\n",
       " ('number', 2),\n",
       " ('boy', 2),\n",
       " ('joined', 2),\n",
       " ('okay', 2),\n",
       " ('feeling', 2),\n",
       " ('darted', 2),\n",
       " ('late', 2),\n",
       " ('make', 2),\n",
       " ('merely', 2),\n",
       " ('sort', 2),\n",
       " ('leapt', 2),\n",
       " ('aside', 2),\n",
       " ('fell', 2),\n",
       " ('cried', 2),\n",
       " ('help', 2),\n",
       " ('hit', 2),\n",
       " ('small', 2),\n",
       " ('group', 2),\n",
       " ('understood', 2),\n",
       " ('chest', 2),\n",
       " ('folded', 2),\n",
       " ('thinking', 2),\n",
       " ('hogwarts:', 2),\n",
       " ('moon', 2),\n",
       " ('spectacles', 2),\n",
       " ('died', 2),\n",
       " ('forgotten', 2),\n",
       " ('bring', 2),\n",
       " ('departure', 2),\n",
       " ('gruffly', 2),\n",
       " ('larger', 2),\n",
       " ('fang', 2),\n",
       " ('galloping', 2),\n",
       " ('alongside', 2),\n",
       " ('wizards', 2),\n",
       " ('mudblood', 2),\n",
       " ('scene', 2),\n",
       " ('tears', 2),\n",
       " ('voldemort', 2),\n",
       " ('granger', 2),\n",
       " ('sword', 2),\n",
       " ('baron', 1),\n",
       " ('round', 1),\n",
       " ('turning', 1),\n",
       " ('hunched', 1),\n",
       " ('nearest', 1),\n",
       " ('lamp', 1),\n",
       " ('hissing', 1),\n",
       " ('remember', 1),\n",
       " ('home', 1),\n",
       " ('facing', 1),\n",
       " ('cared', 1),\n",
       " ('space', 1),\n",
       " ('possible', 1),\n",
       " ('monster', 1),\n",
       " ('earth', 1),\n",
       " ('hanging', 1),\n",
       " ('flushed', 1),\n",
       " ('sweaty', 1),\n",
       " ('faces', 1),\n",
       " ('panted', 1),\n",
       " ('collapsed', 1),\n",
       " ('trembling', 1),\n",
       " ('saving', 1),\n",
       " ('hadn', 1),\n",
       " ('locked', 1),\n",
       " ('reminded', 1),\n",
       " ('noisy', 1),\n",
       " ('quickly', 1),\n",
       " ('play', 1),\n",
       " ('legs', 1),\n",
       " ('recognized', 1),\n",
       " ('locker', 1),\n",
       " ('curse', 1),\n",
       " ('midnight', 1),\n",
       " ('tail', 1),\n",
       " ('wailed', 1),\n",
       " ('desperate', 1),\n",
       " ('exploded', 1),\n",
       " ('idiot', 1),\n",
       " ('words', 1),\n",
       " ('sudden', 1),\n",
       " ('storm', 1),\n",
       " ('clapping', 1),\n",
       " ('lopsided', 1),\n",
       " ('tables', 1),\n",
       " ('squashy', 1),\n",
       " ('pull', 1),\n",
       " ('brilliant', 1),\n",
       " ('smirking', 1),\n",
       " ('mr', 1),\n",
       " ('beaming', 1),\n",
       " ('double', 1),\n",
       " ('sign', 1),\n",
       " ('fumbled', 1),\n",
       " ('bell', 1),\n",
       " ('rang', 1),\n",
       " ('picked', 1),\n",
       " ('copy', 1),\n",
       " ('gilderoy', 1),\n",
       " ('order', 1),\n",
       " ('merlin', 1),\n",
       " ('class', 1),\n",
       " ('member', 1),\n",
       " ('nimbus', 1),\n",
       " ('thousand', 1),\n",
       " ('clatter', 1),\n",
       " ('dashing', 1),\n",
       " ('swinging', 1),\n",
       " ('hurry', 1),\n",
       " ('wow', 1),\n",
       " ('game', 1),\n",
       " ('knight', 1),\n",
       " ('horse', 1),\n",
       " ('dragged', 1),\n",
       " ('important', 1),\n",
       " ('wondering', 1),\n",
       " ('darker', 1),\n",
       " ('swirling', 1),\n",
       " ('attacks', 1),\n",
       " ('urge', 1),\n",
       " ('thinks', 1),\n",
       " ('somewhat', 1),\n",
       " ('awkwardly', 1),\n",
       " ('ghost', 1),\n",
       " ('ravenclaw', 1),\n",
       " ('seizing', 1),\n",
       " ('difficult', 1),\n",
       " ('journey', 1),\n",
       " ('dodging', 1),\n",
       " ('weasleys', 1),\n",
       " ('darkness', 1),\n",
       " ('falling', 1),\n",
       " ('activity', 1),\n",
       " ('tired', 1),\n",
       " ('sadly', 1),\n",
       " ('remembering', 1),\n",
       " ('divided', 1),\n",
       " ('separate', 1),\n",
       " ('dementors', 1),\n",
       " ('things', 1),\n",
       " ('meet', 1),\n",
       " ('anybody', 1),\n",
       " ('entirely', 1),\n",
       " ('sure', 1),\n",
       " ('october', 1),\n",
       " ('halloween', 1),\n",
       " ('excellent', 1),\n",
       " ('zonko', 1),\n",
       " ('jerking', 1),\n",
       " ('chattering', 1),\n",
       " ('older', 1),\n",
       " ('forehead', 1),\n",
       " ('library', 1),\n",
       " ('choice', 1),\n",
       " ('waking', 1),\n",
       " ('grumpily', 1),\n",
       " ('checked', 1),\n",
       " ('starting', 1),\n",
       " ('discussing', 1),\n",
       " ('dropped', 1),\n",
       " ('nervously', 1),\n",
       " ('usual', 1),\n",
       " ('path', 1),\n",
       " ('ended', 1),\n",
       " ('jammed', 1),\n",
       " ('peered', 1),\n",
       " ('bustling', 1),\n",
       " ('importantly', 1),\n",
       " ('arrived', 1),\n",
       " ('sweeping', 1),\n",
       " ('squeezed', 1),\n",
       " ('moved', 1),\n",
       " ('grabbed', 1),\n",
       " ('arm', 1),\n",
       " ('slashed', 1),\n",
       " ('littered', 1),\n",
       " ('map', 1),\n",
       " ('replaced', 1),\n",
       " ('happy', 1),\n",
       " ('spent', 1),\n",
       " ('sneaking', 1),\n",
       " ('breakfast', 1),\n",
       " ('yellow', 1),\n",
       " ('men', 1),\n",
       " ('enjoying', 1),\n",
       " ('couple', 1),\n",
       " ('handle', 1),\n",
       " ('shiny', 1),\n",
       " ('pointless', 1),\n",
       " ('angle', 1),\n",
       " ('accompanied', 1),\n",
       " ('certain', 1),\n",
       " ('informed', 1),\n",
       " ('heel', 1),\n",
       " ('firebolt', 1),\n",
       " ('tin', 1),\n",
       " ('high', 1),\n",
       " ('finish', 1),\n",
       " ('clutched', 1),\n",
       " ('startled', 1),\n",
       " ('eat', 1),\n",
       " ('nightmare', 1),\n",
       " ('telling', 1),\n",
       " ('slammed', 1),\n",
       " ('furiously', 1),\n",
       " ('knife', 1),\n",
       " ('ridiculous', 1),\n",
       " ('possibly', 1),\n",
       " ('gotten', 1),\n",
       " ('finger', 1),\n",
       " ('glaring', 1),\n",
       " ('suspiciously', 1),\n",
       " ('listened', 1),\n",
       " ('piece', 1),\n",
       " ('paper', 1),\n",
       " ('stunned', 1),\n",
       " ('white', 1),\n",
       " ('person', 1),\n",
       " ('mouse', 1),\n",
       " ('holes', 1),\n",
       " ('fired', 1),\n",
       " ('lonely', 1),\n",
       " ('woken', 1),\n",
       " ('thoughtfully', 1),\n",
       " ('kill', 1),\n",
       " ('total', 1),\n",
       " ('furious', 1),\n",
       " ('security', 1),\n",
       " ('fast', 1),\n",
       " ('asleep', 1),\n",
       " ('resting', 1),\n",
       " ('joking', 1),\n",
       " ('heading', 1),\n",
       " ('freedom', 1),\n",
       " ('sentence', 1),\n",
       " ('strode', 1),\n",
       " ('banging', 1),\n",
       " ('prefect', 1),\n",
       " ('crackling', 1),\n",
       " ('carrying', 1),\n",
       " ('fine', 1),\n",
       " ('worry', 1),\n",
       " ('feels', 1),\n",
       " ('normal', 1),\n",
       " ('briefly', 1),\n",
       " ('blast', 1),\n",
       " ('knocked', 1),\n",
       " ('backward', 1),\n",
       " ('wrenched', 1),\n",
       " ('dozen', 1),\n",
       " ('allow', 1),\n",
       " ('cornered', 1),\n",
       " ('brothers', 1),\n",
       " ('frantically', 1),\n",
       " ('resolutely', 1),\n",
       " ('hello', 1),\n",
       " ('instead', 1),\n",
       " ('far', 1),\n",
       " ('badges', 1),\n",
       " ('minute', 1),\n",
       " ('keeping', 1),\n",
       " ('dare', 1),\n",
       " ('slow', 1),\n",
       " ('gasped', 1),\n",
       " ('muttered', 1),\n",
       " ('sleepily', 1),\n",
       " ('opening', 1),\n",
       " ('fourth', 1),\n",
       " ('bowed', 1),\n",
       " ('parvati', 1),\n",
       " ('action', 1),\n",
       " ('wishing', 1),\n",
       " ('winked', 1),\n",
       " ('o', 1),\n",
       " ('fool', 1),\n",
       " ('cho', 1),\n",
       " ('lights', 1),\n",
       " ('irritated', 1),\n",
       " ('dragons', 1),\n",
       " ('bye', 1),\n",
       " ('straight', 1),\n",
       " ('tortured', 1),\n",
       " ('size', 1),\n",
       " ('unpleasant', 1),\n",
       " ('month', 1),\n",
       " ('sticking', 1),\n",
       " ('charm', 1),\n",
       " ('quick', 1),\n",
       " ('bewildered', 1),\n",
       " ('earsplitting', 1),\n",
       " ('lupin', 1),\n",
       " ('calm', 1),\n",
       " ('kitchen', 1),\n",
       " ('seat', 1),\n",
       " ('obviously', 1),\n",
       " ('walking', 1),\n",
       " ('clattering', 1),\n",
       " ('chain', 1),\n",
       " ('deep', 1),\n",
       " ('orders', 1),\n",
       " ('foul', 1),\n",
       " ('hopefully', 1),\n",
       " ('parents', 1),\n",
       " ('sighed', 1),\n",
       " ('wouldn', 1),\n",
       " ('occasionally', 1),\n",
       " ('useful', 1),\n",
       " ('stuffed', 1),\n",
       " ('cage', 1),\n",
       " ('dragging', 1),\n",
       " ('trunk', 1),\n",
       " ('howling', 1),\n",
       " ('rage', 1),\n",
       " ('bothering', 1),\n",
       " ('close', 1),\n",
       " ('bound', 1),\n",
       " ('events', 1),\n",
       " ('graveyard', 1),\n",
       " ('er', 1),\n",
       " ('glumly', 1),\n",
       " ('positively', 1),\n",
       " ('alarmed', 1),\n",
       " ('cabin', 1),\n",
       " ('chairs', 1),\n",
       " ('sense', 1),\n",
       " ('stuff', 1),\n",
       " ('working', 1),\n",
       " ('carefully', 1),\n",
       " ('owlery', 1),\n",
       " ('headless', 1),\n",
       " ('nick', 1),\n",
       " ('drifting', 1),\n",
       " ('coolly', 1),\n",
       " ('hour', 1),\n",
       " ('lousy', 1),\n",
       " ('disheveled', 1),\n",
       " ('realize', 1),\n",
       " ('happen', 1),\n",
       " ('fair', 1),\n",
       " ('giggling', 1),\n",
       " ('madly', 1),\n",
       " ('fashioned', 1),\n",
       " ('senses', 1),\n",
       " ('early', 1),\n",
       " ('ravenclaws', 1),\n",
       " ('west', 1),\n",
       " ('finally', 1),\n",
       " ('creaking', 1),\n",
       " ('pale', 1),\n",
       " ('tracks', 1),\n",
       " ('elf', 1),\n",
       " ('hats', 1),\n",
       " ('defensively', 1),\n",
       " ('clicked', 1),\n",
       " ('tongue', 1),\n",
       " ('grown', 1),\n",
       " ('crouch', 1),\n",
       " ('prevent', 1),\n",
       " ('panic', 1),\n",
       " ('strange', 1),\n",
       " ('instrument', 1),\n",
       " ('shout', 1),\n",
       " ('reappeared', 1),\n",
       " ('news', 1),\n",
       " ('doesn', 1),\n",
       " ('blood', 1),\n",
       " ('coughing', 1),\n",
       " ('armchair', 1),\n",
       " ('thank', 1),\n",
       " ('minerva', 1),\n",
       " ('blue', 1),\n",
       " ('quivered', 1),\n",
       " ('marched', 1),\n",
       " ('beard', 1),\n",
       " ('colors', 1),\n",
       " ('jerk', 1),\n",
       " ('wide', 1),\n",
       " ('giving', 1),\n",
       " ('fake', 1),\n",
       " ('eyeing', 1),\n",
       " ('apprehensively', 1),\n",
       " ('destroyed', 1),\n",
       " ('family', 1),\n",
       " ('knows', 1),\n",
       " ('destroy', 1),\n",
       " ('before:', 1),\n",
       " ('issuing', 1),\n",
       " ('bored', 1),\n",
       " ('disappeared', 1),\n",
       " ('antidotes', 1),\n",
       " ('anti', 1),\n",
       " ('unless', 1),\n",
       " ('qualified', 1),\n",
       " ('witch', 1),\n",
       " ('young', 1),\n",
       " ('performing', 1),\n",
       " ('spot', 1),\n",
       " ('crystal', 1),\n",
       " ('bubbles', 1),\n",
       " ('ceiling', 1),\n",
       " ('vicious', 1),\n",
       " ('pace', 1),\n",
       " ('beds', 1),\n",
       " ('brain', 1),\n",
       " ('questions', 1),\n",
       " ('dreadful', 1),\n",
       " ('ideas', 1),\n",
       " ('snake', 1),\n",
       " ('animagus', 1),\n",
       " ('leaning', 1),\n",
       " ('watching', 1),\n",
       " ('squinting', 1),\n",
       " ('outline', 1),\n",
       " ('occurred', 1),\n",
       " ('probably', 1),\n",
       " ('case', 1),\n",
       " ('attacked', 1),\n",
       " ('dad', 1),\n",
       " ('visited', 1),\n",
       " ('comfort', 1),\n",
       " ('pile', 1),\n",
       " ('rat', 1),\n",
       " ('dropping', 1),\n",
       " ('passing', 1),\n",
       " ('says', 1),\n",
       " ('raising', 1),\n",
       " ('eyebrows', 1),\n",
       " ('interesting', 1),\n",
       " ('roared', 1),\n",
       " ('nosed', 1),\n",
       " ('ministry', 1),\n",
       " ('creatures', 1),\n",
       " ('examining', 1),\n",
       " ('unicorns', 1),\n",
       " ('thoroughly', 1),\n",
       " ('tempered', 1),\n",
       " ('runes', 1),\n",
       " ('exams', 1),\n",
       " ('celebration', 1),\n",
       " ('approaching', 1),\n",
       " ('occasional', 1),\n",
       " ('grunt', 1),\n",
       " ('sleeping', 1),\n",
       " ('surroundings', 1),\n",
       " ('reflected', 1),\n",
       " ('feelings', 1),\n",
       " ('pain', 1),\n",
       " ('quiet', 1),\n",
       " ('shattered', 1),\n",
       " ('pieces', 1),\n",
       " ('yells', 1),\n",
       " ('anger', 1),\n",
       " ('fright', 1),\n",
       " ('snatching', 1),\n",
       " ('hitting', 1),\n",
       " ('noticing', 1),\n",
       " ('start', 1),\n",
       " ('cutting', 1),\n",
       " ('telephone', 1),\n",
       " ('heart', 1),\n",
       " ('sank', 1),\n",
       " ('afraid', 1),\n",
       " ('hoping', 1),\n",
       " ('speak', 1),\n",
       " ('dreaming', 1),\n",
       " ('cough', 1),\n",
       " ('magic', 1),\n",
       " ('strain', 1),\n",
       " ('caused', 1),\n",
       " ('utterly', 1),\n",
       " ('terrified', 1),\n",
       " ('self', 1),\n",
       " ('bounced', 1),\n",
       " ('shaken', 1),\n",
       " ('remained', 1),\n",
       " ('encounter', 1),\n",
       " ('given', 1),\n",
       " ('private', 1),\n",
       " ('proved', 1),\n",
       " ('impossible', 1),\n",
       " ('remove', 1),\n",
       " ('art', 1),\n",
       " ('happened', 1),\n",
       " ('ago', 1),\n",
       " ('wet', 1),\n",
       " ('state', 1),\n",
       " ('considerable', 1),\n",
       " ('course', 1),\n",
       " ('busy', 1),\n",
       " ('quill', 1),\n",
       " ('catching', 1),\n",
       " ('finishing', 1),\n",
       " ('letter', 1),\n",
       " ('luck', 1),\n",
       " ('maybe', 1),\n",
       " ('scrimgeour', 1),\n",
       " ('success', 1),\n",
       " ('subsided', 1),\n",
       " ('suddenly', 1),\n",
       " ('official', 1),\n",
       " ('muggles', 1),\n",
       " ('meeting', 1),\n",
       " ('enchantment', 1),\n",
       " ('ensure', 1),\n",
       " ('owned', 1),\n",
       " ('pureblood', 1),\n",
       " ('vivid', 1),\n",
       " ('shrieking', 1),\n",
       " ('spitting', 1),\n",
       " ('flashed', 1),\n",
       " ('snapped', 1),\n",
       " ('particularly', 1),\n",
       " ('minuscule', 1),\n",
       " ('muttering', 1),\n",
       " ('promptly', 1),\n",
       " ('scarlet', 1),\n",
       " ('hope', 1),\n",
       " ('goes', 1),\n",
       " ('pair', 1),\n",
       " ('leave', 1),\n",
       " ('proceeded', 1),\n",
       " ('step', 1),\n",
       " ('statue', 1),\n",
       " ('trelawney', 1),\n",
       " ('smelled', 1),\n",
       " ('damp', 1),\n",
       " ('stalked', 1),\n",
       " ('undoubtedly', 1),\n",
       " ('pause', 1),\n",
       " ('worst', 1),\n",
       " ('darkly', 1),\n",
       " ('evening', 1),\n",
       " ('soon', 1),\n",
       " ('sinking', 1),\n",
       " ('mane', 1),\n",
       " ('bushy', 1),\n",
       " ('brown', 1),\n",
       " ('whipping', 1),\n",
       " ('unlocked', 1),\n",
       " ('classroom', 1),\n",
       " ('hi', 1),\n",
       " ('fancy', 1),\n",
       " ('thanks', 1),\n",
       " ('precisely', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(item, value) for item, value in contexts[\"portrait\"].items()], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the word 'ghost'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harry', 52),\n",
       " ('said', 36),\n",
       " ('nick', 22),\n",
       " ('t', 20),\n",
       " ('nearly', 20),\n",
       " ('headless', 18),\n",
       " ('know', 15),\n",
       " ('looked', 12),\n",
       " ('ron', 10),\n",
       " ('saw', 9),\n",
       " ('d', 9),\n",
       " ('ve', 9),\n",
       " ('got', 8),\n",
       " ('gryffindor', 8),\n",
       " ('years', 7),\n",
       " ('bloody', 7),\n",
       " ('baron', 7),\n",
       " ('wand', 7),\n",
       " ('cedric', 7),\n",
       " ('dumbledore', 7),\n",
       " ('just', 6),\n",
       " ('don', 6),\n",
       " ('think', 6),\n",
       " ('told', 6),\n",
       " ('slytherin', 6),\n",
       " ('staring', 6),\n",
       " ('eyes', 6),\n",
       " ('professor', 6),\n",
       " ('passed', 6),\n",
       " ('like', 6),\n",
       " ('hermione', 6),\n",
       " ('gray', 6),\n",
       " ('ruff', 5),\n",
       " ('suddenly', 5),\n",
       " ('table', 5),\n",
       " ('potter', 5),\n",
       " ('giving', 5),\n",
       " ('began', 5),\n",
       " ('tower', 5),\n",
       " ('magic', 5),\n",
       " ('binns', 5),\n",
       " ('light', 5),\n",
       " ('held', 5),\n",
       " ('head', 5),\n",
       " ('little', 5),\n",
       " ('solid', 5),\n",
       " ('really', 4),\n",
       " ('hufflepuff', 4),\n",
       " ('hat', 4),\n",
       " ('opposite', 4),\n",
       " ('seen', 4),\n",
       " ('arm', 4),\n",
       " ('need', 4),\n",
       " ('sir', 4),\n",
       " ('gaunt', 4),\n",
       " ('face', 4),\n",
       " ('silver', 4),\n",
       " ('corridor', 4),\n",
       " ('covered', 4),\n",
       " ('wide', 4),\n",
       " ('oh', 4),\n",
       " ('asked', 4),\n",
       " ('away', 4),\n",
       " ('myrtle', 4),\n",
       " ('hair', 4),\n",
       " ('thing', 4),\n",
       " ('hogwarts', 4),\n",
       " ('white', 4),\n",
       " ('stood', 4),\n",
       " ('voldemort', 4),\n",
       " ('end', 4),\n",
       " ('neville', 4),\n",
       " ('come', 4),\n",
       " ('haven', 3),\n",
       " ('peeves', 3),\n",
       " ('say', 3),\n",
       " ('doing', 3),\n",
       " ('wearing', 3),\n",
       " ('fat', 3),\n",
       " ('sat', 3),\n",
       " ('horrible', 3),\n",
       " ('plate', 3),\n",
       " ('good', 3),\n",
       " ('course', 3),\n",
       " ('seamus', 3),\n",
       " ('sitting', 3),\n",
       " ('history', 3),\n",
       " ('taught', 3),\n",
       " ('let', 3),\n",
       " ('direction', 3),\n",
       " ('moaning', 3),\n",
       " ('came', 3),\n",
       " ('help', 3),\n",
       " ('hedwig', 3),\n",
       " ('window', 3),\n",
       " ('man', 3),\n",
       " ('talking', 3),\n",
       " ('wasn', 3),\n",
       " ('surprised', 3),\n",
       " ('drifted', 3),\n",
       " ('mean', 3),\n",
       " ('girl', 3),\n",
       " ('wall', 3),\n",
       " ('floor', 3),\n",
       " ('large', 3),\n",
       " ('room', 3),\n",
       " ('attack', 3),\n",
       " ('crash', 3),\n",
       " ('gryffindors', 3),\n",
       " ('ravenclaw', 3),\n",
       " ('riddle', 3),\n",
       " ('diary', 3),\n",
       " ('diggory', 3),\n",
       " ('looking', 3),\n",
       " ('heard', 3),\n",
       " ('pain', 3),\n",
       " ('body', 3),\n",
       " ('alive', 3),\n",
       " ('gone', 3),\n",
       " ('golden', 3),\n",
       " ('emerged', 3),\n",
       " ('wizard', 3),\n",
       " ('malfoy', 3),\n",
       " ('sure', 3),\n",
       " ('given', 2),\n",
       " ('chances', 2),\n",
       " ('deserves', 2),\n",
       " ('gives', 2),\n",
       " ('bad', 2),\n",
       " ('noticed', 2),\n",
       " ('answered', 2),\n",
       " ('students', 2),\n",
       " ('clapped', 2),\n",
       " ('susan', 2),\n",
       " ('shouted', 2),\n",
       " ('weasley', 2),\n",
       " ('twins', 2),\n",
       " ('earlier', 2),\n",
       " ('patted', 2),\n",
       " ('sudden', 2),\n",
       " ('bit', 2),\n",
       " ('does', 2),\n",
       " ('sadly', 2),\n",
       " ('cut', 2),\n",
       " ('steak', 2),\n",
       " ('eaten', 2),\n",
       " ('myself', 2),\n",
       " ('brothers', 2),\n",
       " ('haired', 2),\n",
       " ('finnigan', 2),\n",
       " ('blank', 2),\n",
       " ('used', 2),\n",
       " ('boring', 2),\n",
       " ('class', 2),\n",
       " ('old', 2),\n",
       " ('m', 2),\n",
       " ('tall', 2),\n",
       " ('gliding', 2),\n",
       " ('started', 2),\n",
       " ('free', 2),\n",
       " ('soft', 2),\n",
       " ('ahead', 2),\n",
       " ('wings', 2),\n",
       " ('moment', 2),\n",
       " ('soared', 2),\n",
       " ('impatiently', 2),\n",
       " ('warning', 2),\n",
       " ('somebody', 2),\n",
       " ('forehead', 2),\n",
       " ('watched', 2),\n",
       " ('crouched', 2),\n",
       " ('walked', 2),\n",
       " ('er', 2),\n",
       " ('horses', 2),\n",
       " ('pack', 2),\n",
       " ('bearded', 2),\n",
       " ('position', 2),\n",
       " ('blowing', 2),\n",
       " ('horn', 2),\n",
       " ('leapt', 2),\n",
       " ('lifted', 2),\n",
       " ('high', 2),\n",
       " ('laughed', 2),\n",
       " ('subject', 2),\n",
       " ('teacher', 2),\n",
       " ('happened', 2),\n",
       " ('way', 2),\n",
       " ('filled', 2),\n",
       " ('safe', 2),\n",
       " ('door', 2),\n",
       " ('flew', 2),\n",
       " ('people', 2),\n",
       " ('dead', 2),\n",
       " ('seats', 2),\n",
       " ('counting', 2),\n",
       " ('school', 2),\n",
       " ('ago', 2),\n",
       " ('memory', 2),\n",
       " ('quietly', 2),\n",
       " ('rolling', 2),\n",
       " ('sleeves', 2),\n",
       " ('turn', 2),\n",
       " ('black', 2),\n",
       " ('quickly', 2),\n",
       " ('seeing', 2),\n",
       " ('things', 2),\n",
       " ('wands', 2),\n",
       " ('shadow', 2),\n",
       " ('skull', 2),\n",
       " ('mr', 2),\n",
       " ('vanished', 2),\n",
       " ('rest', 2),\n",
       " ('particularly', 2),\n",
       " ('chance', 2),\n",
       " ('opinion', 2),\n",
       " ('foot', 2),\n",
       " ('running', 2),\n",
       " ('clutching', 2),\n",
       " ('fear', 2),\n",
       " ('going', 2),\n",
       " ('water', 2),\n",
       " ('shock', 2),\n",
       " ('ripped', 2),\n",
       " ('spirit', 2),\n",
       " ('hand', 2),\n",
       " ('tip', 2),\n",
       " ('tightly', 2),\n",
       " ('thread', 2),\n",
       " ('remained', 2),\n",
       " ('itself', 2),\n",
       " ('correct', 2),\n",
       " ('spoke', 2),\n",
       " ('shaking', 2),\n",
       " ('past', 2),\n",
       " ('feels', 2),\n",
       " ('voice', 2),\n",
       " ('hey', 2),\n",
       " ('cloak', 2),\n",
       " ('floating', 2),\n",
       " ('board', 2),\n",
       " ('long', 2),\n",
       " ('tried', 2),\n",
       " ('tell', 2),\n",
       " ('difference', 2),\n",
       " ('lying', 2),\n",
       " ('tomb', 2),\n",
       " ('dunno', 2),\n",
       " ('wouldn', 2),\n",
       " ('felt', 2),\n",
       " ('length', 2),\n",
       " ('times', 2),\n",
       " ('spoken', 2),\n",
       " ('lady', 2),\n",
       " ('nodded', 2),\n",
       " ('did', 2),\n",
       " ('speak', 2),\n",
       " ('fred', 2),\n",
       " ('new', 1),\n",
       " ('right', 1),\n",
       " ('cheered', 1),\n",
       " ('hannah', 1),\n",
       " ('went', 1),\n",
       " ('sit', 1),\n",
       " ('waving', 1),\n",
       " ('merrily', 1),\n",
       " ('bones', 1),\n",
       " ('yelled', 1),\n",
       " ('feeling', 1),\n",
       " ('plunged', 1),\n",
       " ('eat', 1),\n",
       " ('delicious', 1),\n",
       " ('look', 1),\n",
       " ('watching', 1),\n",
       " ('miss', 1),\n",
       " ('introduced', 1),\n",
       " ('service', 1),\n",
       " ('prefer', 1),\n",
       " ('stiffly', 1),\n",
       " ('interrupted', 1),\n",
       " ('winning', 1),\n",
       " ('slytherins', 1),\n",
       " ('cup', 1),\n",
       " ('row', 1),\n",
       " ('robes', 1),\n",
       " ('stained', 1),\n",
       " ('blood', 1),\n",
       " ('strange', 1),\n",
       " ('plants', 1),\n",
       " ('easily', 1),\n",
       " ('fallen', 1),\n",
       " ('asleep', 1),\n",
       " ('staffroom', 1),\n",
       " ('morning', 1),\n",
       " ('teach', 1),\n",
       " ('leaving', 1),\n",
       " ('freezing', 1),\n",
       " ('forget', 1),\n",
       " ('hissed', 1),\n",
       " ('witch', 1),\n",
       " ('stirring', 1),\n",
       " ('cauldrons', 1),\n",
       " ('wonderful', 1),\n",
       " ('week', 1),\n",
       " ('exam', 1),\n",
       " ('results', 1),\n",
       " ('quills', 1),\n",
       " ('roll', 1),\n",
       " ('parchment', 1),\n",
       " ('couldn', 1),\n",
       " ('whispered', 1),\n",
       " ('listened', 1),\n",
       " ('rustling', 1),\n",
       " ('clinking', 1),\n",
       " ('coming', 1),\n",
       " ('sounds', 1),\n",
       " ('moving', 1),\n",
       " ('reached', 1),\n",
       " ('later', 1),\n",
       " ('alongside', 1),\n",
       " ('story', 1),\n",
       " ('happening', 1),\n",
       " ('dobby', 1),\n",
       " ('deserted', 1),\n",
       " ('muttering', 1),\n",
       " ('breath', 1),\n",
       " ('gloomy', 1),\n",
       " ('ragged', 1),\n",
       " ('chains', 1),\n",
       " ('cheerful', 1),\n",
       " ('knight', 1),\n",
       " ('sticking', 1),\n",
       " ('ghosts', 1),\n",
       " ('died', 1),\n",
       " ('october', 1),\n",
       " ('amazed', 1),\n",
       " ('approached', 1),\n",
       " ('low', 1),\n",
       " ('mouth', 1),\n",
       " ('taste', 1),\n",
       " ('walk', 1),\n",
       " ('expect', 1),\n",
       " ('stronger', 1),\n",
       " ('flavor', 1),\n",
       " ('didn', 1),\n",
       " ('mind', 1),\n",
       " ('hello', 1),\n",
       " ('squat', 1),\n",
       " ('glided', 1),\n",
       " ('half', 1),\n",
       " ('hidden', 1),\n",
       " ('bitterly', 1),\n",
       " ('dungeon', 1),\n",
       " ('burst', 1),\n",
       " ('dozen', 1),\n",
       " ('wildly', 1),\n",
       " ('clap', 1),\n",
       " ('middle', 1),\n",
       " ('dance', 1),\n",
       " ('halted', 1),\n",
       " ('plunging', 1),\n",
       " ('air', 1),\n",
       " ('crowd', 1),\n",
       " ('strode', 1),\n",
       " ('schedule', 1),\n",
       " ('exciting', 1),\n",
       " ('classes', 1),\n",
       " ('entering', 1),\n",
       " ('blackboard', 1),\n",
       " ('ancient', 1),\n",
       " ('shriveled', 1),\n",
       " ('lungs', 1),\n",
       " ('stop', 1),\n",
       " ('screamed', 1),\n",
       " ('mortal', 1),\n",
       " ('run', 1),\n",
       " ('lives', 1),\n",
       " ('real', 1),\n",
       " ('panic', 1),\n",
       " ('curiously', 1),\n",
       " ('fate', 1),\n",
       " ('worry', 1),\n",
       " ('possibly', 1),\n",
       " ('terrible', 1),\n",
       " ('power', 1),\n",
       " ('harm', 1),\n",
       " ('book', 1),\n",
       " ('awkwardly', 1),\n",
       " ('portrait', 1),\n",
       " ('hole', 1),\n",
       " ('immediately', 1),\n",
       " ('friend', 1),\n",
       " ('lee', 1),\n",
       " ('jordan', 1),\n",
       " ('fingers', 1),\n",
       " ('stand', 1),\n",
       " ('lockhart', 1),\n",
       " ('getting', 1),\n",
       " ('feet', 1),\n",
       " ('ways', 1),\n",
       " ('aside', 1),\n",
       " ('pipe', 1),\n",
       " ('miles', 1),\n",
       " ('weird', 1),\n",
       " ('misty', 1),\n",
       " ('shining', 1),\n",
       " ('day', 1),\n",
       " ('older', 1),\n",
       " ('sixteen', 1),\n",
       " ('uncertainly', 1),\n",
       " ('fifty', 1),\n",
       " ('popped', 1),\n",
       " ('walls', 1),\n",
       " ('tables', 1),\n",
       " ('great', 1),\n",
       " ('success', 1),\n",
       " ('pleasant', 1),\n",
       " ('evening', 1),\n",
       " ('mood', 1),\n",
       " ('lupin', 1),\n",
       " ('forgive', 1),\n",
       " ('believing', 1),\n",
       " ('spy', 1),\n",
       " ('grin', 1),\n",
       " ('flitted', 1),\n",
       " ('shall', 1),\n",
       " ('kill', 1),\n",
       " ('dad', 1),\n",
       " ('maybe', 1),\n",
       " ('met', 1),\n",
       " ('mere', 1),\n",
       " ('green', 1),\n",
       " ('spell', 1),\n",
       " ('smoke', 1),\n",
       " ('hufflepuffs', 1),\n",
       " ('far', 1),\n",
       " ('hall', 1),\n",
       " ('pearly', 1),\n",
       " ('dressed', 1),\n",
       " ('tonight', 1),\n",
       " ('usual', 1),\n",
       " ('question', 1),\n",
       " ('utterly', 1),\n",
       " ('food', 1),\n",
       " ('throwing', 1),\n",
       " ('silent', 1),\n",
       " ('person', 1),\n",
       " ('control', 1),\n",
       " ('store', 1),\n",
       " ('amused', 1),\n",
       " ('month', 1),\n",
       " ('ideas', 1),\n",
       " ('writing', 1),\n",
       " ('weekly', 1),\n",
       " ('goblin', 1),\n",
       " ('century', 1),\n",
       " ('amazing', 1),\n",
       " ('seriously', 1),\n",
       " ('goblet', 1),\n",
       " ('reckon', 1),\n",
       " ('trying', 1),\n",
       " ('weeks', 1),\n",
       " ('meeting', 1),\n",
       " ('noise', 1),\n",
       " ('loud', 1),\n",
       " ('wailing', 1),\n",
       " ('nearest', 1),\n",
       " ('party', 1),\n",
       " ('playing', 1),\n",
       " ('musical', 1),\n",
       " ('shut', 1),\n",
       " ('miracle', 1),\n",
       " ('sort', 1),\n",
       " ('extra', 1),\n",
       " ('concentrated', 1),\n",
       " ('supposed', 1),\n",
       " ('starting', 1),\n",
       " ('dancing', 1),\n",
       " ('champions', 1),\n",
       " ('suppose', 1),\n",
       " ('gloomily', 1),\n",
       " ('girls', 1),\n",
       " ('second', 1),\n",
       " ('putting', 1),\n",
       " ('swallowed', 1),\n",
       " ('considerable', 1),\n",
       " ('bubbles', 1),\n",
       " ('cross', 1),\n",
       " ('legged', 1),\n",
       " ('taps', 1),\n",
       " ('usually', 1),\n",
       " ('friends', 1),\n",
       " ('prepared', 1),\n",
       " ('anybody', 1),\n",
       " ('path', 1),\n",
       " ('leads', 1),\n",
       " ('goal', 1),\n",
       " ('red', 1),\n",
       " ('widened', 1),\n",
       " ('dense', 1),\n",
       " ('wormtail', 1),\n",
       " ('shouts', 1),\n",
       " ('larger', 1),\n",
       " ('kept', 1),\n",
       " ('squeezing', 1),\n",
       " ('narrow', 1),\n",
       " ('dream', 1),\n",
       " ('pushing', 1),\n",
       " ('himself', 1),\n",
       " ('fell', 1),\n",
       " ('surveyed', 1),\n",
       " ('web', 1),\n",
       " ('connected', 1),\n",
       " ('appearance', 1),\n",
       " ('guessing', 1),\n",
       " ('limped', 1),\n",
       " ('rustle', 1),\n",
       " ('small', 1),\n",
       " ('time', 1),\n",
       " ('snarled', 1),\n",
       " ('landed', 1),\n",
       " ('lightly', 1),\n",
       " ('cage', 1),\n",
       " ('work', 1),\n",
       " ('halfway', 1),\n",
       " ('house', 1),\n",
       " ('parvati', 1),\n",
       " ('patil', 1),\n",
       " ('lavender', 1),\n",
       " ('brown', 1),\n",
       " ('gave', 1),\n",
       " ('friendly', 1),\n",
       " ('leaning', 1),\n",
       " ('winced', 1),\n",
       " ('uncomfortable', 1),\n",
       " ('lean', 1),\n",
       " ('honor', 1),\n",
       " ('bound', 1),\n",
       " ('saying', 1),\n",
       " ('sorting', 1),\n",
       " ('glad', 1),\n",
       " ('reason', 1),\n",
       " ('common', 1),\n",
       " ('kind', 1),\n",
       " ('wheezy', 1),\n",
       " ('cause', 1),\n",
       " ('severe', 1),\n",
       " ('minutes', 1),\n",
       " ('warm', 1),\n",
       " ('drifting', 1),\n",
       " ('stuck', 1),\n",
       " ('revealing', 1),\n",
       " ('dangerously', 1),\n",
       " ('continued', 1),\n",
       " ('hesitated', 1),\n",
       " ('wizards', 1),\n",
       " ('year', 1),\n",
       " ('pansy', 1),\n",
       " ('indignantly', 1),\n",
       " ('smirk', 1),\n",
       " ('moved', 1),\n",
       " ('bigger', 1),\n",
       " ('better', 1),\n",
       " ('luggage', 1),\n",
       " ('rack', 1),\n",
       " ('conscious', 1),\n",
       " ('ginny', 1),\n",
       " ('dean', 1),\n",
       " ('listening', 1),\n",
       " ('bench', 1),\n",
       " ('darkly', 1),\n",
       " ('silvery', 1),\n",
       " ('mass', 1),\n",
       " ('rose', 1),\n",
       " ('revolving', 1),\n",
       " ('slowly', 1),\n",
       " ('pensieve', 1),\n",
       " ('completely', 1),\n",
       " ('curious', 1),\n",
       " ('circumstances', 1),\n",
       " ('brought', 1),\n",
       " ('yeh', 1),\n",
       " ('o', 1),\n",
       " ('governors', 1),\n",
       " ('hagrid', 1),\n",
       " ('stopped', 1),\n",
       " ('woman', 1),\n",
       " ('serenely', 1),\n",
       " ('resumed', 1),\n",
       " ('hoarse', 1),\n",
       " ('whisper', 1),\n",
       " ('corner', 1),\n",
       " ('apparently', 1),\n",
       " ('impression', 1),\n",
       " ('draco', 1),\n",
       " ('inside', 1),\n",
       " ('hour', 1),\n",
       " ('wondering', 1),\n",
       " ('paper', 1),\n",
       " ('snape', 1),\n",
       " ('bored', 1),\n",
       " ('fixed', 1),\n",
       " ('ask', 1),\n",
       " ('hastily', 1),\n",
       " ('recall', 1),\n",
       " ('night', 1),\n",
       " ('dark', 1),\n",
       " ('spells', 1),\n",
       " ('merely', 1),\n",
       " ('bidding', 1),\n",
       " ('trust', 1),\n",
       " ('aware', 1),\n",
       " ('departed', 1),\n",
       " ('soul', 1),\n",
       " ('left', 1),\n",
       " ('earth', 1),\n",
       " ('test', 1),\n",
       " ('boys', 1),\n",
       " ('bathroom', 1),\n",
       " ('risen', 1),\n",
       " ('toilet', 1),\n",
       " ('midair', 1),\n",
       " ('round', 1),\n",
       " ('glasses', 1),\n",
       " ('remembering', 1),\n",
       " ('words', 1),\n",
       " ('before:', 1),\n",
       " ('want', 1),\n",
       " ('tom', 1),\n",
       " ('death', 1),\n",
       " ('apparent', 1),\n",
       " ('expression', 1),\n",
       " ('explain', 1),\n",
       " ('sent', 1),\n",
       " ('knew', 1),\n",
       " ('precious', 1),\n",
       " ('attacked', 1),\n",
       " ('true', 1),\n",
       " ('destroyed', 1),\n",
       " ('thought', 1),\n",
       " ('feel', 1),\n",
       " ('surely', 1),\n",
       " ('horcruxes', 1),\n",
       " ('paced', 1),\n",
       " ('luna', 1),\n",
       " ('checking', 1),\n",
       " ('marauder', 1),\n",
       " ('map', 1),\n",
       " ('permitted', 1),\n",
       " ('twice', 1),\n",
       " ('pausing', 1),\n",
       " ('allow', 1),\n",
       " ('pass', 1),\n",
       " ('drawing', 1),\n",
       " ('attention', 1),\n",
       " ('expected', 1),\n",
       " ('encounter', 1),\n",
       " ('worst', 1),\n",
       " ('forced', 1),\n",
       " ('finally', 1),\n",
       " ('reaching', 1),\n",
       " ('stairs', 1),\n",
       " ('waiting', 1),\n",
       " ('dear', 1),\n",
       " ('boy', 1),\n",
       " ('grasp', 1),\n",
       " ('thrust', 1),\n",
       " ('icy', 1),\n",
       " ('offended', 1),\n",
       " ('transparent', 1),\n",
       " ('pointing', 1),\n",
       " ('finger', 1),\n",
       " ('caught', 1),\n",
       " ('sight', 1),\n",
       " ('raised', 1),\n",
       " ('eyebrows', 1),\n",
       " ('proud', 1),\n",
       " ('close', 1),\n",
       " ('recognized', 1),\n",
       " ('tone', 1),\n",
       " ('percy', 1),\n",
       " ('brother', 1),\n",
       " ('kneeling', 1),\n",
       " ('stared', 1),\n",
       " ('laugh', 1),\n",
       " ('etched', 1),\n",
       " ('chapter', 1),\n",
       " ('thirty', 1),\n",
       " ('elder', 1),\n",
       " ('world', 1),\n",
       " ('ended', 1),\n",
       " ('battle', 1),\n",
       " ('twig', 1),\n",
       " ('strewn', 1),\n",
       " ('ground', 1),\n",
       " ('marked', 1),\n",
       " ('outer', 1),\n",
       " ('edge', 1),\n",
       " ('forest', 1),\n",
       " ('opened', 1),\n",
       " ('truly', 1),\n",
       " ('flesh', 1),\n",
       " ('resembled', 1),\n",
       " ('closely', 1),\n",
       " ('escaped', 1)]"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(item, value) for item, value in contexts[\"ghost\"].items()], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4623"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = vocab['asked']\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The co-occurrence matrix of a very large corpus should give a meaningful summary of how a word is used in general. A single row of that matrix is already a __word vector__ of size $N$. However such vectors are extremely sparse, and for large corpora the size of $N$ will become unwieldy. We will follow along the paper in designing an algorithm that can compress the word vectors while retaining most of their informational content. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "For the resulting vectors to actually be informative, the source corpus should have a size of at least a few billion words; on the contrary, our corpus enumerates merely a million words, so we can't expect our results to be as great.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity and Stability\n",
    "\n",
    "Our matrix $X$ is very sparse; most of its elements are zero.\n",
    "\n",
    "**Coding 1.1**: Find what the ratio of non-zero elements is.\n",
    "\n",
    "_Hint_: The function `non_zero_ratio` should return a `float` rather than a `FloatTensor`. Remember `.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10844852030277252\n"
     ]
    }
   ],
   "source": [
    "def non_zero_ratio(sparse_matrix: LongTensor) -> float:\n",
    "    xnonZero = torch.count_nonzero(sparse_matrix)\n",
    "    N,M = sparse_matrix.shape\n",
    "    xallValues = N * M\n",
    "    ratio = xnonZero/xallValues\n",
    "    ratio.item()\n",
    "    print(ratio.item())\n",
    "    \n",
    "non_zero_ratio(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will soon need to perform division and find the logarithm of ${X}$. Neither of the two operations are well-defined for $0$. That's why for further processing we want to have a matrix without any zero elements. \n",
    "\n",
    "**Coding 1.2**: Change the matrix's datatype to a `torch.float` and add a small constant to it (e.g. $0.1$) to ensure numerical stability while maintaining sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "d  = torch.tensor([[1., 0.], [0., -1.]])\n",
    "print(torch.count_nonzero(d.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(torch.float) + 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From co-occurrence counts to probabilities\n",
    "From the paper: \n",
    "> Let the matrix of word-word co-occurrence counts be denoted by $X$, whose entries $X_{ij}$ tabulate the number of times word $j$ occurs in the context of word $i$.  Let $X_i$= $\\sum_{k} X_{ik}$ be the number of times any word appears in the context of word $i$. Finally, let $P_{ij} = P(j  | i) =  X_{ij}/X_i$ be the probability that word $j$ appear in the context of word $i$. \n",
    "\n",
    "**Coding 2**: Complete the function `to_probabilities` that accepts a co-occurrence matrix and returns the probability matrix $P$. \n",
    "\n",
    "_Hint_: Remember broadcasting and `torch.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359\n",
      "tensor([[1.2439e-04, 1.2439e-04, 1.2439e-04,  ..., 1.2439e-04, 1.2439e-04,\n",
      "         1.2439e-04],\n",
      "        [4.5067e-05, 4.5067e-05, 4.5067e-05,  ..., 4.5067e-05, 4.5067e-05,\n",
      "         4.5067e-05],\n",
      "        [9.7191e-05, 9.7191e-05, 9.7191e-05,  ..., 9.7191e-05, 9.7191e-05,\n",
      "         9.7191e-05],\n",
      "        ...,\n",
      "        [1.3177e-04, 1.3177e-04, 1.3177e-04,  ..., 1.3177e-04, 1.3177e-04,\n",
      "         1.3177e-04],\n",
      "        [1.1602e-04, 1.1602e-04, 1.1602e-04,  ..., 1.1602e-04, 1.1602e-04,\n",
      "         1.1602e-04],\n",
      "        [7.0328e-05, 7.0328e-05, 7.0328e-05,  ..., 7.0328e-05, 7.0328e-05,\n",
      "         7.0328e-05]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def to_probabilities(count_matrix: FloatTensor) -> FloatTensor:\n",
    "    total_amout = len(count_matrix)\n",
    "    print(total_amout)\n",
    "    sum_ = torch.sum(count_matrix,1, keepdim=True, dtype = float)\n",
    "    return(count_matrix / sum_)\n",
    "    \n",
    "P = to_probabilities(X)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probing words\n",
    "\n",
    "From the paper:\n",
    "> Consider two words $i$ and $j$ that exhibit a particular aspect of interest. The relationship of these words can be examined by studying the ratio of their co-occurrence probabilities with various probe words, $k$.  For words $k$ related to $i$ but not $j$, we expect the ratio $P_{ik}/P_{jk}$ will be large.  Similarly, for words $k$ related to $j$ but not $i$, the ratio should be small. For words $k$ that are either related to both $i$ and $j$, or to neither, the ratio should be close to one.\n",
    "\n",
    "**Coding 3.1**: Complete the function `query` that accepts two words $w_i$ and $w_j$, a vocab $V$ and a probability matrix ${P}$, maps each word to its corresponding index and returns the probability $P(j  |  i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(word_i: str, word_j: str, vocab: Dict[str, int], probability_matrix: FloatTensor) -> float:  \n",
    "    i = vocab[word_i]\n",
    "    j = vocab[word_j]\n",
    "    return(probability_matrix[i][j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding 3.2**: Then, complete the function `probe` that accepts three words $w_i$, $w_j$ and $w_k$, a vocab $V$ and a probability matrix ${P}$, calls `query` and returns the ratio $P(k |  i) / P(k  |  j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe(word_i: str, word_j: str, word_k: str, vocab: Dict[str, int], probability_matrix: FloatTensor) -> float:\n",
    "    Pki = query( word_i,word_k, vocab, probability_matrix)\n",
    "    Pkj = query( word_j, word_k, vocab, probability_matrix)\n",
    "    return Pki/Pkj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's probe a few words and examine whether the authors' claim holds even for our (tiny) corpus. Feel free to add your own word triplets and experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tea wand spell tensor(0.4226, dtype=torch.float64)\n",
      "tea wand cup tensor(24.6131, dtype=torch.float64)\n",
      "\n",
      "voldemort hagrid curse tensor(8.7108, dtype=torch.float64)\n",
      "voldemort hagrid beast tensor(0.5588, dtype=torch.float64)\n",
      "\n",
      "mcgonagall snape potions tensor(0.0036, dtype=torch.float64)\n",
      "mcgonagall snape transfiguration tensor(43.7188, dtype=torch.float64)\n",
      "\n",
      "hedwig scabbers owl tensor(5.6266, dtype=torch.float64)\n",
      "hedwig scabbers rat tensor(0.0178, dtype=torch.float64)\n",
      "\n",
      "ron hermione book tensor(0.6783, dtype=torch.float64)\n",
      "ron hermione red tensor(2.0383, dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"tea\", \"wand\", \"spell\", probe(\"tea\", \"wand\", \"spell\", vocab, P))\n",
    "print(\"tea\", \"wand\", \"cup\", probe(\"tea\", \"wand\", \"cup\", vocab, P))\n",
    "print()\n",
    "\n",
    "print(\"voldemort\", \"hagrid\", \"curse\", probe(\"voldemort\", \"hagrid\", \"curse\", vocab, P))\n",
    "print(\"voldemort\", \"hagrid\", \"beast\", probe(\"voldemort\", \"hagrid\", \"beast\", vocab, P))\n",
    "print()\n",
    "\n",
    "print(\"mcgonagall\", \"snape\", \"potions\", probe(\"mcgonagall\", \"snape\", \"potions\", vocab, P))\n",
    "print(\"mcgonagall\", \"snape\", \"transfiguration\", probe(\"mcgonagall\", \"snape\", \"transfiguration\", vocab, P))\n",
    "print()\n",
    "\n",
    "print(\"hedwig\", \"scabbers\", \"owl\", probe(\"hedwig\", \"scabbers\", \"owl\", vocab, P))\n",
    "print(\"hedwig\", \"scabbers\", \"rat\", probe(\"hedwig\", \"scabbers\", \"rat\", vocab, P))\n",
    "print()\n",
    "\n",
    "print(\"ron\", \"hermione\", \"book\", probe(\"ron\", \"hermione\", \"book\", vocab, P))\n",
    "print(\"ron\", \"hermione\", \"red\", probe(\"ron\", \"hermione\", \"red\", vocab, P))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation 1**: Give a brief interpretation of the results you got. Do they correspond to your expectations? Why or why not?\n",
    "\n",
    "*Hint*: When do we expect the ratio value to be high, low or close to 1? Refer to the GloVe paper for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if we tried probing out-of-domain words? Use the words that the authors report in the paper as discriminative for \"ice\" and \"steam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ice steam ice tensor(0.9024, dtype=torch.float64)\n",
      "ice steam steam tensor(0.9024, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "word1 = \"ice\"\n",
    "word2 = \"steam\"\n",
    "print(\"ice\", \"steam\", word1, probe(\"ice\", \"steam\", word1, vocab, P))\n",
    "print(\"ice\", \"steam\", word2, probe(\"ice\", \"steam\", word2, vocab, P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation 2**: Give an interpretation of the results you got. Do they match what the authors report in the paper? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        ...,\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]])"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Vectors\n",
    "\n",
    "Now, we would like to convert these long sparse vectors into short dense ones. \n",
    "\n",
    "The conversion should be such that the probability ratios we inspected earlier may still be reconstructed via some (for now, unknown) operation $F$ on the dense vectors.\n",
    "\n",
    "To restrict the search space over potential functions, the authors impose a number of constraints they think $F$ should satisfy:\n",
    "1. > While $F$ could be taken to be a complicated function parameterized by, e.g., a neural network, doing so would obfuscate the linear structure we are trying to capture. $F$ should be dot-product based.\n",
    "2. > The distinction between a word and a context word is arbitrary and we are free to exchange the two roles. To do so consistently, we must not only exchange $w \\leftrightarrow \\tilde{w}$ but also $X \\leftrightarrow X^T$.\n",
    "3. > It should be well-defined for all values in $X$.\n",
    "\n",
    "Given these three constraints, each word $i$ in our vocabulary is represented by four vectors:\n",
    "1. A vector $w_i \\in \\mathbb{R}^D$\n",
    "2. A bias $b_i \\in \\mathbb{R}$\n",
    "3. A context vector $\\tilde{w}_i \\in \\mathbb{R}^D$\n",
    "4. A context bias $\\tilde{b}_i \\in \\mathbb{R}$\n",
    "\n",
    "and $F: \\mathbb{R}^D \\times \\mathbb{R} \\times \\mathbb{R}^D \\times \\mathbb{R} \\to \\mathbb{R}$ is defined as:\n",
    "\n",
    "$F(w_i, \\tilde{w}_k, b_i, \\tilde{b}_k) = w_i^T\\tilde{w}_k + b_i + \\tilde{b}_k$.\n",
    "\n",
    "Or equivalently the least squares error $J$ is minimized, where:\n",
    "\n",
    "$J = \\sum_{i,j=1}^{V} f(X_{ij})(w_{i}^T\\tilde{w}_j + b_i + \\tilde{b}_j - log(X_{ij}))^2$\n",
    "\n",
    "with $f$ being a weighting function, defined as \n",
    "\n",
    "$f: \\mathbb{R} \\to \\mathbb{R} = \\begin{cases}\n",
    "    (x/x_{max})^\\alpha, & \\text{if $x<x_{max}$}\\\\\n",
    "    1, & \\text{otherwise}.\n",
    "  \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting Function\n",
    "\n",
    "Let's start with the last part. \n",
    "\n",
    "**Coding 4**: Complete the weighting function `weight_fn` which accepts a co-occurrence matrix ${X}$, a maximum value $x_{max}$ and a fractional power $alpha$, and returns the weighted co-occurrence matrix $f({X})$.\n",
    "\n",
    "Then, compute $\\text{X_weighted}$, the matrix ${X}$ after weighting, using the paper's suggested parameters. \n",
    "\n",
    "_Hint_: Note that $f$ is defined pointwise, so our weighting function should also be pointwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        ...,\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056]])\n"
     ]
    }
   ],
   "source": [
    "def weight_fn(X: FloatTensor, x_max: int, alpha: float) -> FloatTensor:\n",
    "    return(torch.where(X<x_max,(X/x_max)**alpha,torch.ones_like(X)))\n",
    "    \n",
    "X_weighted = weight_fn(X,100, 0.75)\n",
    "\n",
    "print(X_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to get an understanding of how the weighting affects different co-occurrence values (high and low). Think of some word pairs with high and low co-occurrence and look them up in $X$ and in $\\text{X_weighted}$ to get a better idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        ...,\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056],\n",
      "        [0.0056, 0.0056, 0.0056,  ..., 0.0056, 0.0056, 0.0056]])\n"
     ]
    }
   ],
   "source": [
    "print(X_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Next step is to write the loss function. \n",
    "\n",
    "We can write it as a pointwise function, apply it iteratively over each pair of words and then sum the result; that's however extremely inefficient. \n",
    "\n",
    "Inspecting the formulation of $J$, it is fairly straight-forward to see that it can be immediately implemented using matrix-matrix operations, as:\n",
    "\n",
    "$J = \\sum_{i,j=1}^{V}f(\\mathbf{X})\\cdot(W\\tilde{W}^T + b + \\tilde{b}^T - log(X))^2$,\n",
    "\n",
    "where $W$, $\\tilde{W}$ are the $N \\times D$ matrices containing the $D$-dimensional vectors of all our $N$ vocabulary words, and $b$, $\\tilde{b}$ are the $N \\times 1$ matrices containing the $1$-dimensional biases of our words.\n",
    "\n",
    "**Coding 5**: Complete `loss_fn`, a function that accepts a weighted co-occurrence matrix $f({X})$, the word vectors and biases $W$, $\\tilde{W}$, $b$, $\\tilde{b}$ and the co-occurrence matrix ${X}$, and computes $J$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-1.,  1.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.ones(1,4)\n",
    "aa = torch.transpose(aa,0,1)\n",
    "c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n",
    "print(torch.max(c))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(\n",
    "    X_weighted: FloatTensor, \n",
    "    W: FloatTensor, \n",
    "    W_context: FloatTensor, \n",
    "    B: FloatTensor, \n",
    "    B_context: FloatTensor, \n",
    "    X: FloatTensor\n",
    ") -> FloatTensor:\n",
    "    w_inc = (W @ W_context.T)\n",
    "    biased_ = (B + B_context.T)\n",
    "    log_ = (torch.log(X))\n",
    "    power_ = (w_inc + biased_ - log_)**2\n",
    "    return torch.sum( X_weighted* (power_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe\n",
    "\n",
    "We have the normalized co-occurrence matrix ${X}$, the weighting function $f$, and the loss function $J$ that implements $F$.\n",
    "\n",
    "What we need now is a mapping from words (or word ids) to unique, parametric and trainable vectors. \n",
    "\n",
    "Torch provides this abstraction in the form of [Embedding layers](https://pytorch.org/docs/stable/nn.html#embedding). Each such layer may be viewed as a stand-alone network that can be optimized using the standard procedure we have already seen. \n",
    "\n",
    "We will utilize the `nn.Module` class to contain all our embedding layers and streamline their joint optimization.\n",
    "The container class will be responsible for a few things:\n",
    "\n",
    "1. **Coding 6.1**: Wrapping the embedding layers:\n",
    "    1. A vector embedding that maps words to $w \\in \\mathbb{R}^D$\n",
    "    2. A context vector embedding that maps words to $w_c \\in \\mathbb{R}^D$\n",
    "    3. A bias embedding that maps words to $b \\in \\mathbb{R}^1$\n",
    "    4. A context bias embedding that maps words to $b_c \\in \\mathbb{R}^1$\n",
    "2. **Coding 6.2**: Implementing `forward`, a function that accepts a weighted co-occurrence matrix $f(X)$, the co-occurrence matrix $X$, then finds the embeddings of all words and finally calls `loss_fn` as defined above.\n",
    "3. **Coding 7**: Implementing `get_vectors`, a function that receives no input and produces the word vectors and context word vectors of all words, adds them together and returns the result, in accordance with the paper:\n",
    "> ...With this in mind, we choose to use the sum $W + \\tilde{W}$ as our word vectors.\n",
    "\n",
    "Complete the network class following the above specifications.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7267,  1.4357,  1.9874],\n",
      "         [ 1.1507, -1.0090, -0.7447]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7267,  1.4357,  1.9874],\n",
       "        [-0.4069, -0.0590,  0.7430],\n",
       "        [ 1.1507, -1.0090, -0.7447],\n",
       "        [-0.2066, -0.1802, -0.4056],\n",
       "        [ 0.1226,  0.6572, -0.2621],\n",
       "        [-1.0414, -0.9945, -1.3998],\n",
       "        [ 0.2007, -0.0257,  0.2038],\n",
       "        [-0.2236,  0.1520,  0.3110],\n",
       "        [ 1.7258, -1.2690,  0.0749],\n",
       "        [ 0.7579,  0.1074, -2.2189]], requires_grad=True)"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = torch.nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[0,2]])\n",
    "print(embedding(input))\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(torch.nn.Module):\n",
    "    def __init__(self, vocab: Dict[str, int], vector_dim: int=30, device: str=\"cpu\") -> None:\n",
    "        super(GloVe, self).__init__()\n",
    "        self.device = device\n",
    "        self.vocab_len = len(vocab)\n",
    "        self.w = torch.nn.Embedding(num_embeddings = self.vocab_len, embedding_dim  =vector_dim).to(self.device)\n",
    "        self.wc = torch.nn.Embedding(num_embeddings = self.vocab_len, embedding_dim  =vector_dim).to(self.device)\n",
    "        self.b = torch.nn.Embedding(self.vocab_len,1).to(self.device)\n",
    "        self.bc = torch.nn.Embedding(self.vocab_len, 1).to(self.device)\n",
    "        \n",
    "    def forward(self, X_weighted: FloatTensor, X: FloatTensor) -> FloatTensor:\n",
    "        embedding_input = torch.arange(self.vocab_len).to(self.device)\n",
    "        W = self.w(embedding_input)\n",
    "        Wc = self.wc(embedding_input)\n",
    "        b_ = self.b(embedding_input)\n",
    "        b_c = self.bc(embedding_input)\n",
    "        return(loss_fn (X_weighted , W, Wc, b_, b_c , X))\n",
    "        \n",
    "\n",
    "    def get_vectors(self) -> FloatTensor:\n",
    "        embedding_input = torch.arange(self.vocab_len).to(self.device)\n",
    "        w_word_vector = self.w(embedding_input)\n",
    "        Wc_word_vector = self.wc(embedding_input)\n",
    "        return (w_word_vector + Wc_word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Everything is in place; now we may begin optimizing our embedding layers (and in doing so, the vectors they assign). \n",
    "\n",
    "**Coding 8.1**: Instantiate the network class you just defined using $D = 30$. Then instantiate an `Adam` optimizer with a learning rate of 0.05 and train your network for 300 epochs.\n",
    "\n",
    "When writing the training script, remember that your network's forward pass is __already__ computing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-711-d5bfb6a0b234>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-711-d5bfb6a0b234>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    opt.step() # gradient computation\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "network = GloVe(vocab)\n",
    "opt =torch.optim.Adam(network.parameters(), lr=0.05)\n",
    "\n",
    "num_epochs = 50\n",
    "losses = []\n",
    "epoches =[]\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss =  network(X_weighted,X) # loss computation (optionally print it out)\n",
    "    loss.backward() # back-propagation\n",
    "    if i %10 ==0:\n",
    "    opt.step() # gradient computation \n",
    "    losses.append(loss)\n",
    "    opt.zero_grad() # gradient reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding 8.2**: Plot the losses and examine the learning curve. Is its shape what you would expect it to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your plotting here\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot( losses)\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation (Similarity)\n",
    "\n",
    "Curious to see what this network has learned? Let's perform a simple validation experiment. \n",
    "\n",
    "We will check which words the models considers the most similar to other words. To that end, we need a notion of __similarity__. One of the most common measures of similarity in high dimensional vector spaces is the cosine similarity. \n",
    "\n",
    "The cosine similarity of two vectors $\\vec{a}, \\vec{b}$ is given as:\n",
    "$$sim(\\vec{a}, \\vec{b}) = \\frac{\\vec{a}\\cdot \\vec{b}}{|\\vec{a}|_2 \\cdot |\\vec{b}|_2}$$\n",
    "\n",
    "where $|\\vec{x}|_2$ is the $L_2$-norm of the $\\vec{x}$.\n",
    "\n",
    "The function `similarity` below accepts two words, a vocabulary and the network's output vectors, and computes the similarity between these two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word_i: str, word_j: str, vocab: Dict[str, int], vectors: FloatTensor) -> float:\n",
    "    i = vocab[word_i]\n",
    "    j = vocab[word_j] \n",
    "    v_i = vectors[i] / torch.norm(vectors[i], p=2)  # a/|a|\n",
    "    v_j = vectors[j] / torch.norm(vectors[j], p=2)  # b/|b|\n",
    "    sim = torch.mm(v_i.view(1, -1), v_j.view(-1, 1)).item()\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out some examples. Consider the word pairs below and, optionally, add your own word pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'cruciatus' and 'imperius' is: 0.22437463700771332\n",
      "Similarity between 'avada' and 'kedavra' is: 0.3462338149547577\n",
      "Similarity between 'hogwarts' and 'school' is: 0.5040878057479858\n",
      "Similarity between 'goblin' and 'hagrid' is: 0.5106287002563477\n",
      "Similarity between 'giant' and 'hagrid' is: 0.5409942269325256\n"
     ]
    }
   ],
   "source": [
    "word_vectors = network.get_vectors().detach()\n",
    "\n",
    "for pair in [\n",
    "    (\"cruciatus\", \"imperius\"), \n",
    "    (\"avada\", \"kedavra\"), \n",
    "    (\"hogwarts\", \"school\"), \n",
    "    (\"goblin\", \"hagrid\"), \n",
    "    (\"giant\", \"hagrid\"),\n",
    "]:\n",
    "    \n",
    "    print(\"Similarity between '{}' and '{}' is: {}\".\n",
    "          format(pair[0], pair[1], similarity(pair[0], pair[1], vocab, word_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation 3**: Give a brief interpretation of the results. Do the scores correspond well to your perceived similarity of these word pairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3832, 3833, 3834, 3835, 3836, 3837, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3848, 3849, 3850, 3851, 3852, 3853, 3854, 3855, 3856, 3857, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3867, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3889, 3890, 3891, 3892, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304, 4305, 4306, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4617, 4618, 4619, 4620, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4633, 4634, 4635, 4636, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4649, 4650, 4651, 4652, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4671, 4672, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4699, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4782, 4783, 4784, 4785, 4786, 4787, 4788, 4789, 4790, 4791, 4792, 4793, 4794, 4795, 4796, 4797, 4798, 4799, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4807, 4808, 4809, 4810, 4811, 4812, 4813, 4814, 4815, 4816, 4817, 4818, 4819, 4820, 4821, 4822, 4823, 4824, 4825, 4826, 4827, 4828, 4829, 4830, 4831, 4832, 4833, 4834, 4835, 4836, 4837, 4838, 4839, 4840, 4841, 4842, 4843, 4844, 4845, 4846, 4847, 4848, 4849, 4850, 4851, 4852, 4853, 4854, 4855, 4856, 4857, 4858, 4859, 4860, 4861, 4862, 4863, 4864, 4865, 4866, 4867, 4868, 4869, 4870, 4871, 4872, 4873, 4874, 4875, 4876, 4877, 4878, 4879, 4880, 4881, 4882, 4883, 4884, 4885, 4886, 4887, 4888, 4889, 4890, 4891, 4892, 4893, 4894, 4895, 4896, 4897, 4898, 4899, 4900, 4901, 4902, 4903, 4904, 4905, 4906, 4907, 4908, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4917, 4918, 4919, 4920, 4921, 4922, 4923, 4924, 4925, 4926, 4927, 4928, 4929, 4930, 4931, 4932, 4933, 4934, 4935, 4936, 4937, 4938, 4939, 4940, 4941, 4942, 4943, 4944, 4945, 4946, 4947, 4948, 4949, 4950, 4951, 4952, 4953, 4954, 4955, 4956, 4957, 4958, 4959, 4960, 4961, 4962, 4963, 4964, 4965, 4966, 4967, 4968, 4969, 4970, 4971, 4972, 4973, 4974, 4975, 4976, 4977, 4978, 4979, 4980, 4981, 4982, 4983, 4984, 4985, 4986, 4987, 4988, 4989, 4990, 4991, 4992, 4993, 4994, 4995, 4996, 4997, 4998, 4999, 5000, 5001, 5002, 5003, 5004, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5012, 5013, 5014, 5015, 5016, 5017, 5018, 5019, 5020, 5021, 5022, 5023, 5024, 5025, 5026, 5027, 5028, 5029, 5030, 5031, 5032, 5033, 5034, 5035, 5036, 5037, 5038, 5039, 5040, 5041, 5042, 5043, 5044, 5045, 5046, 5047, 5048, 5049, 5050, 5051, 5052, 5053, 5054, 5055, 5056, 5057, 5058, 5059, 5060, 5061, 5062, 5063, 5064, 5065, 5066, 5067, 5068, 5069, 5070, 5071, 5072, 5073, 5074, 5075, 5076, 5077, 5078, 5079, 5080, 5081, 5082, 5083, 5084, 5085, 5086, 5087, 5088, 5089, 5090, 5091, 5092, 5093, 5094, 5095, 5096, 5097, 5098, 5099, 5100, 5101, 5102, 5103, 5104, 5105, 5106, 5107, 5108, 5109, 5110, 5111, 5112, 5113, 5114, 5115, 5116, 5117, 5118, 5119, 5120, 5121, 5122, 5123, 5124, 5125, 5126, 5127, 5128, 5129, 5130, 5131, 5132, 5133, 5134, 5135, 5136, 5137, 5138, 5139, 5140, 5141, 5142, 5143, 5144, 5145, 5146, 5147, 5148, 5149, 5150, 5151, 5152, 5153, 5154, 5155, 5156, 5157, 5158, 5159, 5160, 5161, 5162, 5163, 5164, 5165, 5166, 5167, 5168, 5169, 5170, 5171, 5172, 5173, 5174, 5175, 5176, 5177, 5178, 5179, 5180, 5181, 5182, 5183, 5184, 5185, 5186, 5187, 5188, 5189, 5190, 5191, 5192, 5193, 5194, 5195, 5196, 5197, 5198, 5199, 5200, 5201, 5202, 5203, 5204, 5205, 5206, 5207, 5208, 5209, 5210, 5211, 5212, 5213, 5214, 5215, 5216, 5217, 5218, 5219, 5220, 5221, 5222, 5223, 5224, 5225, 5226, 5227, 5228, 5229, 5230, 5231, 5232, 5233, 5234, 5235, 5236, 5237, 5238, 5239, 5240, 5241, 5242, 5243, 5244, 5245, 5246, 5247, 5248, 5249, 5250, 5251, 5252, 5253, 5254, 5255, 5256, 5257, 5258, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5271, 5272, 5273, 5274, 5275, 5276, 5277, 5278, 5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288, 5289, 5290, 5291, 5292, 5293, 5294, 5295, 5296, 5297, 5298, 5299, 5300, 5301, 5302, 5303, 5304, 5305, 5306, 5307, 5308, 5309, 5310, 5311, 5312, 5313, 5314, 5315, 5316, 5317, 5318, 5319, 5320, 5321, 5322, 5323, 5324, 5325, 5326, 5327, 5328, 5329, 5330, 5331, 5332, 5333, 5334, 5335, 5336, 5337, 5338, 5339, 5340, 5341, 5342, 5343, 5344, 5345, 5346, 5347, 5348, 5349, 5350, 5351, 5352, 5353, 5354, 5355, 5356, 5357, 5358])"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the similarities of one word against all other words in the corpus, we may rewrite the above equation as:\n",
    "$$sim(\\vec{w}, \\mathbf{C}) = \\frac{\\vec{w}\\cdot \\mathbf{C}}{|\\vec{w}|_2 \\cdot |\\mathbf{C}|_2}$$\n",
    "\n",
    "**Coding 9**: Using `similarity` as a reference, write `similarities`, which accepts one word, a vocabulary and the network's output vectors and computes the similarity between the word and the entire corpus.\n",
    "\n",
    "_Hint_: $\\mathbf{C} \\in \\mathbb{R}^{N, D}$, $\\vec{w} \\in \\mathbb{R}^{1, D}$, $sim(\\vec{w}, \\mathbf{C}) \\in \\mathbb{R}^{1, N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarities(word_i: str, vocab: Dict[str, int], vectors: FloatTensor) -> FloatTensor:\n",
    "    i = vocab[word_i]\n",
    "    v_i = vectors[i] / torch.norm(vectors[i], p=2)  # a/|a|\n",
    "    v_j = vectors / torch.norm(vectors, p=2)  # b/|b|\n",
    "    uns_vi = v_i.unsqueeze(0)\n",
    "\n",
    "    sim = (torch.mm(uns_vi, v_j.T))\n",
    "    return(sim)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can manipulate the word vectors to find out what the corpus-wide most similar words to a query word are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word_i: str, vocab: Dict[str, int], vectors: FloatTensor, k: int) -> List[str]:\n",
    "    sims = similarities(word_i, vocab, vectors)\n",
    "    _, topi = sims.topk(dim=-1, k=k)\n",
    "    topi = topi.view(-1).cpu().numpy().tolist()\n",
    "    inv = {v: i for i, v in vocab.items()}\n",
    "    return [inv[i] for i in topi if inv[i] != word_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'forbidden': ['t', 'quidditch', 'corridor', 'inside', 'ron']\n",
      "Most similar words to 'myrtle': ['ron', 'eyes', 'quidditch', 'snape', 'hagrid']\n",
      "Most similar words to 'gryffindor': ['harry', 'people', 'hermione', 't', 'ron', 'got']\n",
      "Most similar words to 'wand': ['harry', 'hermione', 'snape', 'eyes', 'malfoy', 't']\n",
      "Most similar words to 'quidditch': ['ron', 'people', 't', 'snape', 'eyes']\n",
      "Most similar words to 'marauder': ['holidays', 'need', 'ron', 'people', 'advanced']\n",
      "Most similar words to 'horcrux': ['ron', 'eyes', 'people', 't', 'got', 'having']\n",
      "Most similar words to 'phoenix': ['ron', 'laugh', 'snape', 'eyes', 'thank']\n",
      "Most similar words to 'triwizard': ['dumbledore', 'd', 'harry', 'm', 'reply', 'having']\n",
      "Most similar words to 'screaming': ['forward', 'katie', 'gaze', 'jinx', 'violently']\n",
      "Most similar words to 'letter': ['ron', 'snape', 'away', 'room', 'got']\n"
     ]
    }
   ],
   "source": [
    "for word in [\n",
    "    \"forbidden\", \"myrtle\", \"gryffindor\", \"wand\", \"quidditch\", \"marauder\",\n",
    "    \"horcrux\", \"phoenix\", \"triwizard\", \"screaming\", \"letter\"\n",
    "]:\n",
    "    print(\"Most similar words to '{}': {}\".format(word, most_similar(word, vocab, word_vectors, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation 4**: Interpret the results.\n",
    "- Do these most similar words make sense (are they actually similar to the query words)? \n",
    "- Are there any patterns you can see in the \"errors\" (the words that you woudn't consider actually similar to the query word)? \n",
    "- Would you say that the model captures similarity, relatedness, both or neither?\n",
    "- Any other observations are welcome.\n",
    "\n",
    "Illustrate your answers with examples from your model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flavor': 0,\n",
       " 'party': 1,\n",
       " 'mistress': 2,\n",
       " 'new': 3,\n",
       " 'weird': 4,\n",
       " 'pots': 5,\n",
       " 'prodding': 6,\n",
       " 'apparated': 7,\n",
       " 'pressing': 8,\n",
       " 'alastor': 9,\n",
       " 'argue': 10,\n",
       " 'kettle': 11,\n",
       " 'article': 12,\n",
       " 'oncoming': 13,\n",
       " 'stretched': 14,\n",
       " 'knuts': 15,\n",
       " 'squeeze': 16,\n",
       " 'faint': 17,\n",
       " 'gathered': 18,\n",
       " 'charges': 19,\n",
       " 'behavior': 20,\n",
       " 'broomstick': 21,\n",
       " 'urge': 22,\n",
       " 'collided': 23,\n",
       " 'laid': 24,\n",
       " 'steam': 25,\n",
       " 'newspaper': 26,\n",
       " 'flatly': 27,\n",
       " 'longer': 28,\n",
       " 'tip': 29,\n",
       " 'padfoot': 30,\n",
       " 'shallow': 31,\n",
       " 'hey': 32,\n",
       " 'says': 33,\n",
       " 'jam': 34,\n",
       " 'slimy': 35,\n",
       " 'brave': 36,\n",
       " 'stamping': 37,\n",
       " 'possibility': 38,\n",
       " 'corners': 39,\n",
       " 'country': 40,\n",
       " 'sudden': 41,\n",
       " 'centaurs': 42,\n",
       " 'fears': 43,\n",
       " 'hallway': 44,\n",
       " 'crackling': 45,\n",
       " 'um': 46,\n",
       " 'twins': 47,\n",
       " 'zero': 48,\n",
       " 'driven': 49,\n",
       " 'stock': 50,\n",
       " 'meat': 51,\n",
       " 'strode': 52,\n",
       " 'cause': 53,\n",
       " 'sounds': 54,\n",
       " 'totalus': 55,\n",
       " 'began': 56,\n",
       " 'karkaroff': 57,\n",
       " 'brutal': 58,\n",
       " 'pure': 59,\n",
       " 'floors': 60,\n",
       " 'hatred': 61,\n",
       " 'issue': 62,\n",
       " 'panted': 63,\n",
       " 'serpent': 64,\n",
       " 'lightly': 65,\n",
       " 'sent': 66,\n",
       " 'occlumency': 67,\n",
       " 'honest': 68,\n",
       " 'quality': 69,\n",
       " 'sherry': 70,\n",
       " 'thanks': 71,\n",
       " 'wider': 72,\n",
       " 'risk': 73,\n",
       " 'arrogant': 74,\n",
       " 'stunned': 75,\n",
       " 'secrets': 76,\n",
       " 'longbottom': 77,\n",
       " 'cheerful': 78,\n",
       " 'fixedly': 79,\n",
       " 'dead': 80,\n",
       " 'utterly': 81,\n",
       " 'pronounced': 82,\n",
       " 'stan': 83,\n",
       " 'flooded': 84,\n",
       " 'thief': 85,\n",
       " 'aloud': 86,\n",
       " 'fred': 87,\n",
       " 'sticking': 88,\n",
       " 'dangling': 89,\n",
       " 'bore': 90,\n",
       " 'thought': 91,\n",
       " 'dedalus': 92,\n",
       " 'faded': 93,\n",
       " 'raising': 94,\n",
       " 'undertone': 95,\n",
       " 'followers': 96,\n",
       " 'candle': 97,\n",
       " 'fox': 98,\n",
       " 'west': 99,\n",
       " 'feeling': 100,\n",
       " 'scabior': 101,\n",
       " 'barty': 102,\n",
       " 'papers': 103,\n",
       " 'erupted': 104,\n",
       " 'behave': 105,\n",
       " 'mainly': 106,\n",
       " 'bouncing': 107,\n",
       " 'pansy': 108,\n",
       " 'fleeting': 109,\n",
       " 'adult': 110,\n",
       " 'blink': 111,\n",
       " 'howled': 112,\n",
       " 'tells': 113,\n",
       " 'egypt': 114,\n",
       " 'torn': 115,\n",
       " 'daresay': 116,\n",
       " 'panic': 117,\n",
       " 'direction': 118,\n",
       " 'colder': 119,\n",
       " 'moving': 120,\n",
       " 'entirely': 121,\n",
       " 'capable': 122,\n",
       " 'robe': 123,\n",
       " 'wand:': 124,\n",
       " 'resigned': 125,\n",
       " 'visit': 126,\n",
       " 'bits': 127,\n",
       " 'dodging': 128,\n",
       " 'months': 129,\n",
       " 'irritably': 130,\n",
       " 'fixing': 131,\n",
       " 'event': 132,\n",
       " 'stadium': 133,\n",
       " 'nodded': 134,\n",
       " 'mistakes': 135,\n",
       " 'patted': 136,\n",
       " 'marched': 137,\n",
       " 'wings': 138,\n",
       " 'furniture': 139,\n",
       " 'drowning': 140,\n",
       " 'irritable': 141,\n",
       " 'hollow': 142,\n",
       " 'bushy': 143,\n",
       " 'trained': 144,\n",
       " 'shrink': 145,\n",
       " 'passageway': 146,\n",
       " 'howl': 147,\n",
       " 'leanne': 148,\n",
       " 'movements': 149,\n",
       " 'silence': 150,\n",
       " 'kidding': 151,\n",
       " 'alarmed': 152,\n",
       " 'ragged': 153,\n",
       " 'contrary': 154,\n",
       " 'personal': 155,\n",
       " 'teenage': 156,\n",
       " 'slightly': 157,\n",
       " 'furtive': 158,\n",
       " 'mastered': 159,\n",
       " 'dinner': 160,\n",
       " 'yesterday': 161,\n",
       " 'reparo': 162,\n",
       " 'snap': 163,\n",
       " 'refusing': 164,\n",
       " 'innocent': 165,\n",
       " 'supply': 166,\n",
       " 'unfolded': 167,\n",
       " 'toilet': 168,\n",
       " 'recognize': 169,\n",
       " 'alongside': 170,\n",
       " 'felix': 171,\n",
       " 'whispered': 172,\n",
       " 'runcorn': 173,\n",
       " 'doors': 174,\n",
       " 'remorse': 175,\n",
       " 'hallows': 176,\n",
       " 'poured': 177,\n",
       " 'earth': 178,\n",
       " 'traitor': 179,\n",
       " 'dabbing': 180,\n",
       " 'livid': 181,\n",
       " 'forcing': 182,\n",
       " 'letters': 183,\n",
       " 'ringing': 184,\n",
       " 'blinking': 185,\n",
       " 'triumphantly': 186,\n",
       " 'transform': 187,\n",
       " 'convinced': 188,\n",
       " 'window': 189,\n",
       " 'contents': 190,\n",
       " 'brain': 191,\n",
       " 'patting': 192,\n",
       " 'slow': 193,\n",
       " 'petrified': 194,\n",
       " 'enclosure': 195,\n",
       " 'ludo': 196,\n",
       " 'conjured': 197,\n",
       " 'boarhound': 198,\n",
       " 'messed': 199,\n",
       " 'hexes': 200,\n",
       " 'p': 201,\n",
       " 'bother': 202,\n",
       " 'spun': 203,\n",
       " 'sausages': 204,\n",
       " 'leap': 205,\n",
       " 'clump': 206,\n",
       " 'marauder': 207,\n",
       " 'attempt': 208,\n",
       " 'headquarters': 209,\n",
       " 'archway': 210,\n",
       " 'suspicion': 211,\n",
       " 'crumple': 212,\n",
       " 'hooded': 213,\n",
       " 'arrival': 214,\n",
       " 'tortured': 215,\n",
       " 'mother': 216,\n",
       " 'egg': 217,\n",
       " 'mark': 218,\n",
       " 'similar': 219,\n",
       " 'chart': 220,\n",
       " 'jammed': 221,\n",
       " 'moran': 222,\n",
       " 'glances': 223,\n",
       " 'defense': 224,\n",
       " 'shuffled': 225,\n",
       " 'earnestly': 226,\n",
       " 'dean': 227,\n",
       " 'scored': 228,\n",
       " 'mug': 229,\n",
       " 'commentary': 230,\n",
       " 'hippogriff': 231,\n",
       " 'fourth': 232,\n",
       " 'jaws': 233,\n",
       " 'shrieking': 234,\n",
       " 'missed': 235,\n",
       " 'stop': 236,\n",
       " 'burst': 237,\n",
       " 'sprout': 238,\n",
       " 'informed': 239,\n",
       " 'appointed': 240,\n",
       " 'moved': 241,\n",
       " 'entering': 242,\n",
       " 'idea': 243,\n",
       " 'lower': 244,\n",
       " 'intense': 245,\n",
       " 'sharply': 246,\n",
       " 'highest': 247,\n",
       " 'sunlight': 248,\n",
       " 'bustling': 249,\n",
       " 'stomach': 250,\n",
       " 'focus': 251,\n",
       " 'baby': 252,\n",
       " 'courtyard': 253,\n",
       " 'single': 254,\n",
       " 'jaw': 255,\n",
       " 'burning': 256,\n",
       " 'fetch': 257,\n",
       " 'handle': 258,\n",
       " 'open': 259,\n",
       " '1': 260,\n",
       " 'attacking': 261,\n",
       " 'needed': 262,\n",
       " 'ensure': 263,\n",
       " 'unhappy': 264,\n",
       " 'lunged': 265,\n",
       " 'blame': 266,\n",
       " 'wake': 267,\n",
       " 'attempts': 268,\n",
       " 'charge': 269,\n",
       " 'believes': 270,\n",
       " 'widening': 271,\n",
       " 'enforcement': 272,\n",
       " 'quaffle': 273,\n",
       " 'extendable': 274,\n",
       " 'anythin': 275,\n",
       " 'handbag': 276,\n",
       " 'expectations': 277,\n",
       " 'yellowish': 278,\n",
       " 'shrieked': 279,\n",
       " 'fully': 280,\n",
       " 'fright': 281,\n",
       " 'outta': 282,\n",
       " 'fate': 283,\n",
       " 'fortunately': 284,\n",
       " 'massaging': 285,\n",
       " 'bloody': 286,\n",
       " 'march': 287,\n",
       " 'knelt': 288,\n",
       " 'resolutely': 289,\n",
       " 'explosion': 290,\n",
       " 'sectumsempra': 291,\n",
       " 'curtains': 292,\n",
       " 'scanning': 293,\n",
       " 'offering': 294,\n",
       " 'spoken': 295,\n",
       " 'borns': 296,\n",
       " 'dramatic': 297,\n",
       " 'range': 298,\n",
       " 'rolling': 299,\n",
       " 'thrown': 300,\n",
       " 'drank': 301,\n",
       " 'bad': 302,\n",
       " 'gleam': 303,\n",
       " 'caused': 304,\n",
       " 'hmm': 305,\n",
       " 'happen': 306,\n",
       " 'forefinger': 307,\n",
       " 'rattled': 308,\n",
       " 'standard': 309,\n",
       " 'footsteps': 310,\n",
       " 'flow': 311,\n",
       " 'hearty': 312,\n",
       " 'stove': 313,\n",
       " 'gesture': 314,\n",
       " 'straightaway': 315,\n",
       " 'overheard': 316,\n",
       " 'rabbit': 317,\n",
       " 'riddle': 318,\n",
       " 'fall': 319,\n",
       " 'awkwardly': 320,\n",
       " 'delacour': 321,\n",
       " 'match': 322,\n",
       " 'checked': 323,\n",
       " 'feverishly': 324,\n",
       " 'fashion': 325,\n",
       " 'cowering': 326,\n",
       " 'decided': 327,\n",
       " 'stride': 328,\n",
       " 'non': 329,\n",
       " 'unaware': 330,\n",
       " 'widely': 331,\n",
       " 'neck': 332,\n",
       " 'monday': 333,\n",
       " 'marchbanks': 334,\n",
       " 'chattering': 335,\n",
       " 'sodden': 336,\n",
       " 'hufflepuff': 337,\n",
       " 'allowed': 338,\n",
       " 'scattering': 339,\n",
       " 'starry': 340,\n",
       " 'concern': 341,\n",
       " 'repaired': 342,\n",
       " 'process': 343,\n",
       " 'briefly': 344,\n",
       " 'rucksack': 345,\n",
       " 'accident': 346,\n",
       " 'gliding': 347,\n",
       " 'drawn': 348,\n",
       " 'threatening': 349,\n",
       " 'succeeded': 350,\n",
       " 'rights': 351,\n",
       " 'demanded': 352,\n",
       " 'beg': 353,\n",
       " 'surrounded': 354,\n",
       " 'driver': 355,\n",
       " 'sure': 356,\n",
       " 'stored': 357,\n",
       " 'curved': 358,\n",
       " 'skinny': 359,\n",
       " 'squid': 360,\n",
       " 'omnioculars': 361,\n",
       " 'feelings': 362,\n",
       " 'rarely': 363,\n",
       " 'excuse': 364,\n",
       " 'treasure': 365,\n",
       " 'awoke': 366,\n",
       " 'spirit': 367,\n",
       " 'lump': 368,\n",
       " 'steaming': 369,\n",
       " 'plinth': 370,\n",
       " 'thud': 371,\n",
       " 'flaw': 372,\n",
       " 'shriveled': 373,\n",
       " 'loose': 374,\n",
       " 'mane': 375,\n",
       " 'loyal': 376,\n",
       " 'choose': 377,\n",
       " 'mounted': 378,\n",
       " 'roger': 379,\n",
       " 'anxious': 380,\n",
       " 'vampire': 381,\n",
       " 'git': 382,\n",
       " 'gellert': 383,\n",
       " 'fuss': 384,\n",
       " 'finch': 385,\n",
       " 'fragments': 386,\n",
       " 'knobbly': 387,\n",
       " 'motion': 388,\n",
       " 'draw': 389,\n",
       " 'detention': 390,\n",
       " 'searching': 391,\n",
       " 'mission': 392,\n",
       " 'kingsley': 393,\n",
       " 'friendship': 394,\n",
       " 'aha': 395,\n",
       " 'instance': 396,\n",
       " 'triumphant': 397,\n",
       " 'instruments': 398,\n",
       " 'tentacles': 399,\n",
       " 'committed': 400,\n",
       " 'phoenix': 401,\n",
       " 'instead': 402,\n",
       " 'unmistakable': 403,\n",
       " 'whip': 404,\n",
       " 'knitted': 405,\n",
       " 'honestly': 406,\n",
       " 'restricted': 407,\n",
       " 'rim': 408,\n",
       " 'resting': 409,\n",
       " 'interjected': 410,\n",
       " 'grade': 411,\n",
       " 'lazily': 412,\n",
       " 'suppress': 413,\n",
       " 'inches': 414,\n",
       " 'punished': 415,\n",
       " 'stunning': 416,\n",
       " 'pleased': 417,\n",
       " 'blankly': 418,\n",
       " 'taught': 419,\n",
       " 'preparing': 420,\n",
       " 'fond': 421,\n",
       " 'safely': 422,\n",
       " 'blackthorn': 423,\n",
       " 'office': 424,\n",
       " 'appreciate': 425,\n",
       " 'wrenched': 426,\n",
       " 'markings': 427,\n",
       " 'righ': 428,\n",
       " 'breeds': 429,\n",
       " 'struggling': 430,\n",
       " 'leaking': 431,\n",
       " 'directly': 432,\n",
       " 'shakily': 433,\n",
       " 'request': 434,\n",
       " 'heartily': 435,\n",
       " 'shining': 436,\n",
       " 'containing': 437,\n",
       " 'corridors': 438,\n",
       " 'divination': 439,\n",
       " 'sooner': 440,\n",
       " 'morning': 441,\n",
       " 'tiny': 442,\n",
       " 'chance': 443,\n",
       " 'unlikely': 444,\n",
       " 'gryffindor': 445,\n",
       " 'feared': 446,\n",
       " 'miss': 447,\n",
       " 'throw': 448,\n",
       " 'spitting': 449,\n",
       " 'outline': 450,\n",
       " 'troll': 451,\n",
       " 'i': 452,\n",
       " 'shapes': 453,\n",
       " 'guests': 454,\n",
       " 'bridge': 455,\n",
       " 'suffer': 456,\n",
       " 'swapped': 457,\n",
       " 'flicking': 458,\n",
       " 'beam': 459,\n",
       " 'assure': 460,\n",
       " 'dry': 461,\n",
       " 'example': 462,\n",
       " 'choked': 463,\n",
       " 'trunks': 464,\n",
       " 'bidding': 465,\n",
       " 'watery': 466,\n",
       " 'reappearing': 467,\n",
       " 'joking': 468,\n",
       " 'recall': 469,\n",
       " 'suit': 470,\n",
       " 'grandfather': 471,\n",
       " 'genius': 472,\n",
       " 'astonishment': 473,\n",
       " 'delightedly': 474,\n",
       " 'weak': 475,\n",
       " 'ran': 476,\n",
       " 'beard': 477,\n",
       " 'view': 478,\n",
       " 'lookout': 479,\n",
       " 'goes': 480,\n",
       " 'potato': 481,\n",
       " 'facts': 482,\n",
       " 'dodged': 483,\n",
       " 'talent': 484,\n",
       " 'built': 485,\n",
       " 'flustered': 486,\n",
       " 'cake': 487,\n",
       " 'bite': 488,\n",
       " 'fourteen': 489,\n",
       " 'symbols': 490,\n",
       " 'homework': 491,\n",
       " 'slit': 492,\n",
       " 'forehead': 493,\n",
       " 'grades': 494,\n",
       " 'firstly': 495,\n",
       " 'man': 496,\n",
       " 'need': 497,\n",
       " 'davies': 498,\n",
       " 'yeah': 499,\n",
       " 'viktor': 500,\n",
       " 'international': 501,\n",
       " 'apparate': 502,\n",
       " 'slug': 503,\n",
       " 'veritaserum': 504,\n",
       " 'puffed': 505,\n",
       " 'merpeople': 506,\n",
       " 'paper': 507,\n",
       " 'snatching': 508,\n",
       " 'disgusting': 509,\n",
       " 'merely': 510,\n",
       " 'cares': 511,\n",
       " 'ave': 512,\n",
       " 'bike': 513,\n",
       " 'coldly': 514,\n",
       " 'protective': 515,\n",
       " 'leader': 516,\n",
       " 'magazine': 517,\n",
       " 'smell': 518,\n",
       " 'teams': 519,\n",
       " 'hidden': 520,\n",
       " 'favorites': 521,\n",
       " 'rescued': 522,\n",
       " 'peeves': 523,\n",
       " 'tying': 524,\n",
       " 'shut': 525,\n",
       " 'elf': 526,\n",
       " 'discussed': 527,\n",
       " 'sorcerer': 528,\n",
       " 'tartan': 529,\n",
       " 'kedavra': 530,\n",
       " 'animagus': 531,\n",
       " 'deadly': 532,\n",
       " 'disbelief': 533,\n",
       " 'nodding': 534,\n",
       " 'greenhouses': 535,\n",
       " 'marble': 536,\n",
       " 'silk': 537,\n",
       " 'squeak': 538,\n",
       " 'lights': 539,\n",
       " 'chat': 540,\n",
       " 'slide': 541,\n",
       " 'beater': 542,\n",
       " 'shivered': 543,\n",
       " 'grinding': 544,\n",
       " 'shaken': 545,\n",
       " 'special': 546,\n",
       " 'reminded': 547,\n",
       " 'floo': 548,\n",
       " 'present': 549,\n",
       " 'solid': 550,\n",
       " 'lockhart': 551,\n",
       " 'maliciously': 552,\n",
       " 'n': 553,\n",
       " 'tails': 554,\n",
       " 'thirty': 555,\n",
       " 'sulky': 556,\n",
       " 'prepare': 557,\n",
       " 'try': 558,\n",
       " 'pouring': 559,\n",
       " 'apologize': 560,\n",
       " 'giving': 561,\n",
       " 'seized': 562,\n",
       " 'seriously': 563,\n",
       " 'pureblood': 564,\n",
       " 'snitch': 565,\n",
       " 'sounding': 566,\n",
       " 'hello': 567,\n",
       " 'mad': 568,\n",
       " 'believed': 569,\n",
       " 'bit': 570,\n",
       " 'chicken': 571,\n",
       " 'brushing': 572,\n",
       " 'liar': 573,\n",
       " 'said': 574,\n",
       " 'distinctly': 575,\n",
       " 'rowling': 576,\n",
       " 'moonlight': 577,\n",
       " 'group': 578,\n",
       " 'wipe': 579,\n",
       " 'staff': 580,\n",
       " 'hall': 581,\n",
       " 'towel': 582,\n",
       " 'assistant': 583,\n",
       " 'police': 584,\n",
       " 'eagle': 585,\n",
       " 'increasingly': 586,\n",
       " 'learned': 587,\n",
       " 'kiss': 588,\n",
       " 'night': 589,\n",
       " 'notice': 590,\n",
       " 'minute': 591,\n",
       " 'nicked': 592,\n",
       " 'chased': 593,\n",
       " 'curses': 594,\n",
       " 'im': 595,\n",
       " 'figg': 596,\n",
       " 'decorated': 597,\n",
       " 'clearer': 598,\n",
       " 'scuttled': 599,\n",
       " 'exploded': 600,\n",
       " 'slipped': 601,\n",
       " 'heavily': 602,\n",
       " 'skiving': 603,\n",
       " 'headmistresses': 604,\n",
       " 'rack': 605,\n",
       " 'cover': 606,\n",
       " 'glow': 607,\n",
       " 'aching': 608,\n",
       " 'snare': 609,\n",
       " 'oak': 610,\n",
       " 'possess': 611,\n",
       " 'blackened': 612,\n",
       " 'fast': 613,\n",
       " 'grayish': 614,\n",
       " 'confused': 615,\n",
       " 'stun': 616,\n",
       " 'opposite': 617,\n",
       " 'gripped': 618,\n",
       " 'dark': 619,\n",
       " 'signature': 620,\n",
       " 'spell': 621,\n",
       " 'bellowed': 622,\n",
       " 'twig': 623,\n",
       " 'knocker': 624,\n",
       " 'seconds': 625,\n",
       " 'patronus': 626,\n",
       " 'mysteries': 627,\n",
       " 'potion': 628,\n",
       " 'hundreds': 629,\n",
       " 'leaned': 630,\n",
       " 'courtroom': 631,\n",
       " 'vanish': 632,\n",
       " 'bulging': 633,\n",
       " 'guarding': 634,\n",
       " 'member': 635,\n",
       " 'helping': 636,\n",
       " 'corrected': 637,\n",
       " 'bet': 638,\n",
       " 'split': 639,\n",
       " 'forced': 640,\n",
       " 'rumbling': 641,\n",
       " 'poor': 642,\n",
       " 'rooted': 643,\n",
       " 'generally': 644,\n",
       " 'chasing': 645,\n",
       " 'lightning': 646,\n",
       " 'plate': 647,\n",
       " 'magnified': 648,\n",
       " 'snide': 649,\n",
       " 'weed': 650,\n",
       " 'depths': 651,\n",
       " 'prat': 652,\n",
       " 'belongs': 653,\n",
       " 'continued': 654,\n",
       " 'burkes': 655,\n",
       " 'pounded': 656,\n",
       " 'occupied': 657,\n",
       " 'stowed': 658,\n",
       " 'tears': 659,\n",
       " 'shocking': 660,\n",
       " 'gillyweed': 661,\n",
       " 'mud': 662,\n",
       " 'wishes': 663,\n",
       " 'chamber': 664,\n",
       " 'strangely': 665,\n",
       " 'student': 666,\n",
       " 'cup': 667,\n",
       " 'spoke': 668,\n",
       " 'sniggering': 669,\n",
       " 'rounding': 670,\n",
       " 'total': 671,\n",
       " 'hasn': 672,\n",
       " 'suspended': 673,\n",
       " 'kendra': 674,\n",
       " 'inside': 675,\n",
       " 'page': 676,\n",
       " 'hogwarts': 677,\n",
       " 'price': 678,\n",
       " 'massive': 679,\n",
       " 'buckled': 680,\n",
       " 'prickling': 681,\n",
       " 'asleep': 682,\n",
       " 'flicked': 683,\n",
       " 'problem': 684,\n",
       " 'responsibility': 685,\n",
       " 'green': 686,\n",
       " 'lure': 687,\n",
       " 'bend': 688,\n",
       " 'luck': 689,\n",
       " 'sword': 690,\n",
       " 'reported': 691,\n",
       " 'poster': 692,\n",
       " 'looked': 693,\n",
       " 'handwriting': 694,\n",
       " 'band': 695,\n",
       " 'congratulations': 696,\n",
       " 'caught': 697,\n",
       " 'chosen': 698,\n",
       " 'alecto': 699,\n",
       " 'mistaken': 700,\n",
       " 'cursed': 701,\n",
       " 'run': 702,\n",
       " 'masked': 703,\n",
       " 'mouthful': 704,\n",
       " 'toad': 705,\n",
       " 'makes': 706,\n",
       " 'observed': 707,\n",
       " 'prime': 708,\n",
       " 'society': 709,\n",
       " 'upside': 710,\n",
       " 'shifting': 711,\n",
       " 'crucio': 712,\n",
       " 'teddy': 713,\n",
       " 'clattering': 714,\n",
       " 'foul': 715,\n",
       " 'resisting': 716,\n",
       " 'hangings': 717,\n",
       " 'performed': 718,\n",
       " 'puffy': 719,\n",
       " 'reserved': 720,\n",
       " 'hurry': 721,\n",
       " 'breathed': 722,\n",
       " 'bravery': 723,\n",
       " 'glowed': 724,\n",
       " 'loving': 725,\n",
       " 'granger': 726,\n",
       " 'badge': 727,\n",
       " 'calm': 728,\n",
       " 'portkey': 729,\n",
       " 'sold': 730,\n",
       " 'grinned': 731,\n",
       " 'handkerchief': 732,\n",
       " 'thousands': 733,\n",
       " 'enjoyable': 734,\n",
       " 'features': 735,\n",
       " 'frankly': 736,\n",
       " 'flask': 737,\n",
       " 'matches': 738,\n",
       " 'floating': 739,\n",
       " 'manor': 740,\n",
       " 'frail': 741,\n",
       " 'frighten': 742,\n",
       " 'pillowcase': 743,\n",
       " 'enchanted': 744,\n",
       " 'cushions': 745,\n",
       " 'magic': 746,\n",
       " 'bats': 747,\n",
       " 'alley': 748,\n",
       " 'grew': 749,\n",
       " 'rounded': 750,\n",
       " 'bellatrix': 751,\n",
       " 'sniffed': 752,\n",
       " 'collecting': 753,\n",
       " 'hell': 754,\n",
       " 'later': 755,\n",
       " 'previous': 756,\n",
       " 'advised': 757,\n",
       " 'screech': 758,\n",
       " 'sweaty': 759,\n",
       " 'tipped': 760,\n",
       " 'write': 761,\n",
       " 'cut': 762,\n",
       " 'dungbombs': 763,\n",
       " 'sang': 764,\n",
       " 'mend': 765,\n",
       " 'went': 766,\n",
       " 'lips': 767,\n",
       " 'memory': 768,\n",
       " 'improvement': 769,\n",
       " 'hovering': 770,\n",
       " 'resist': 771,\n",
       " 'neville': 772,\n",
       " 'written': 773,\n",
       " 'relief': 774,\n",
       " 'pushing': 775,\n",
       " 'sitting': 776,\n",
       " 'banging': 777,\n",
       " 'gone': 778,\n",
       " 'damn': 779,\n",
       " 'bundle': 780,\n",
       " 'destroy': 781,\n",
       " 'ice': 782,\n",
       " 'charm': 783,\n",
       " 'progress': 784,\n",
       " 'unusually': 785,\n",
       " 'cloud': 786,\n",
       " 'hiding': 787,\n",
       " 'veela': 788,\n",
       " 'eye': 789,\n",
       " 'k': 790,\n",
       " 'jump': 791,\n",
       " 'sons': 792,\n",
       " 'introduced': 793,\n",
       " 'compartment': 794,\n",
       " 'goggling': 795,\n",
       " 'trusted': 796,\n",
       " 'fresh': 797,\n",
       " 'afraid': 798,\n",
       " 'clinking': 799,\n",
       " 'transfixed': 800,\n",
       " 'learn': 801,\n",
       " 'worth': 802,\n",
       " 'miles': 803,\n",
       " 'cracking': 804,\n",
       " 'related': 805,\n",
       " 'mounting': 806,\n",
       " 'position': 807,\n",
       " 'nearer': 808,\n",
       " 'decision': 809,\n",
       " 'loathing': 810,\n",
       " 'world': 811,\n",
       " 'triumph': 812,\n",
       " 'hide': 813,\n",
       " 'real': 814,\n",
       " 'seventh': 815,\n",
       " 'island': 816,\n",
       " 'stricken': 817,\n",
       " 'piles': 818,\n",
       " 'plain': 819,\n",
       " 'check': 820,\n",
       " 'treacle': 821,\n",
       " 'wheezing': 822,\n",
       " 'scratching': 823,\n",
       " 'shouted': 824,\n",
       " 'incredibly': 825,\n",
       " 'staffroom': 826,\n",
       " 'neighbors': 827,\n",
       " 'gilderoy': 828,\n",
       " 'trolley': 829,\n",
       " 'photographs': 830,\n",
       " 'upset': 831,\n",
       " 'sources': 832,\n",
       " 'bark': 833,\n",
       " 'nails': 834,\n",
       " 'dying': 835,\n",
       " 'version': 836,\n",
       " 'giggling': 837,\n",
       " 'spy': 838,\n",
       " 'fixed': 839,\n",
       " 'burrow': 840,\n",
       " 'calmly': 841,\n",
       " 'hilt': 842,\n",
       " 'doe': 843,\n",
       " 'forming': 844,\n",
       " 'sleeping': 845,\n",
       " 'smoothed': 846,\n",
       " 'pajamas': 847,\n",
       " 'awed': 848,\n",
       " 'ones': 849,\n",
       " 'considering': 850,\n",
       " 'fragment': 851,\n",
       " 'flamel': 852,\n",
       " 'continue': 853,\n",
       " 'dozen': 854,\n",
       " 'disapparate': 855,\n",
       " 'louder': 856,\n",
       " 'worn': 857,\n",
       " 'pointless': 858,\n",
       " 'shadow': 859,\n",
       " 'apple': 860,\n",
       " 'exasperation': 861,\n",
       " 'community': 862,\n",
       " 'nimbus': 863,\n",
       " 'success': 864,\n",
       " 'frantic': 865,\n",
       " 'ghostly': 866,\n",
       " 'failed': 867,\n",
       " 'whereabouts': 868,\n",
       " 'forgetting': 869,\n",
       " 'happened': 870,\n",
       " 'ear': 871,\n",
       " 'lucius': 872,\n",
       " 'false': 873,\n",
       " 'click': 874,\n",
       " 'tale': 875,\n",
       " 'grindylows': 876,\n",
       " 'firmly': 877,\n",
       " '': 878,\n",
       " 'older': 879,\n",
       " 'unknown': 880,\n",
       " 'happiness': 881,\n",
       " 'firebolt': 882,\n",
       " 'girlfriend': 883,\n",
       " 'meetings': 884,\n",
       " 'lined': 885,\n",
       " 'slithering': 886,\n",
       " 'admitted': 887,\n",
       " 'fairly': 888,\n",
       " 'drained': 889,\n",
       " 'bench': 890,\n",
       " 'parkinson': 891,\n",
       " 'creaking': 892,\n",
       " 'lamp': 893,\n",
       " 'horrified': 894,\n",
       " 'milk': 895,\n",
       " 'breathe': 896,\n",
       " 'eyed': 897,\n",
       " 'thoughts': 898,\n",
       " 'crossly': 899,\n",
       " 'h': 900,\n",
       " 'difficult': 901,\n",
       " 'lie': 902,\n",
       " 'relationship': 903,\n",
       " 'brim': 904,\n",
       " 'loomed': 905,\n",
       " 'squares': 906,\n",
       " 'retreated': 907,\n",
       " 'raining': 908,\n",
       " 'insisted': 909,\n",
       " 'pensieve': 910,\n",
       " 'sun': 911,\n",
       " 'library': 912,\n",
       " 'greatly': 913,\n",
       " 'cream': 914,\n",
       " 'improve': 915,\n",
       " 'fool': 916,\n",
       " 'snakelike': 917,\n",
       " 'filled': 918,\n",
       " 'improved': 919,\n",
       " 'generations': 920,\n",
       " 'surrounding': 921,\n",
       " 'now:': 922,\n",
       " 'dismissively': 923,\n",
       " 'paws': 924,\n",
       " 'worse': 925,\n",
       " 'youngest': 926,\n",
       " 'ern': 927,\n",
       " 'inner': 928,\n",
       " 'lake': 929,\n",
       " 'addressed': 930,\n",
       " 'eggs': 931,\n",
       " 'chickens': 932,\n",
       " 'beak': 933,\n",
       " 'puzzled': 934,\n",
       " 'defensive': 935,\n",
       " 'gloom': 936,\n",
       " 'dense': 937,\n",
       " 'guards': 938,\n",
       " 'scratch': 939,\n",
       " 'blast': 940,\n",
       " 'mumbled': 941,\n",
       " 'flesh': 942,\n",
       " 'fluttering': 943,\n",
       " 'tea': 944,\n",
       " 'welcome': 945,\n",
       " 'pacing': 946,\n",
       " 'determinedly': 947,\n",
       " 'pelted': 948,\n",
       " 'witnesses': 949,\n",
       " 'covering': 950,\n",
       " 'telling': 951,\n",
       " 'seek': 952,\n",
       " 'tha': 953,\n",
       " 'inherited': 954,\n",
       " 'distinct': 955,\n",
       " 'crystal': 956,\n",
       " 'gloomy': 957,\n",
       " 'gazing': 958,\n",
       " 'place': 959,\n",
       " 'voldemort': 960,\n",
       " 'leapt': 961,\n",
       " 'slithered': 962,\n",
       " 'blind': 963,\n",
       " 'satisfied': 964,\n",
       " 'trelawney': 965,\n",
       " 'heaved': 966,\n",
       " 'year': 967,\n",
       " 'smart': 968,\n",
       " 'square': 969,\n",
       " 'cards': 970,\n",
       " 'inquiry': 971,\n",
       " 'powerful': 972,\n",
       " 'brandy': 973,\n",
       " 'surprised': 974,\n",
       " 'tracked': 975,\n",
       " 'field': 976,\n",
       " 'truth': 977,\n",
       " 'unicorn': 978,\n",
       " 'exit': 979,\n",
       " 'spying': 980,\n",
       " 'owned': 981,\n",
       " 'draught': 982,\n",
       " 'rid': 983,\n",
       " 'finish': 984,\n",
       " 'underage': 985,\n",
       " 'peering': 986,\n",
       " 'tank': 987,\n",
       " 'fought': 988,\n",
       " 'feed': 989,\n",
       " 'nearest': 990,\n",
       " 'smirk': 991,\n",
       " 'case': 992,\n",
       " 'sugar': 993,\n",
       " 'tensely': 994,\n",
       " 'rumble': 995,\n",
       " 'twitching': 996,\n",
       " 'scrambled': 997,\n",
       " 'screwed': 998,\n",
       " 'upward': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall it's quite impressive; we managed to encode a meaningful portion of the corpus statistics in only $30$ numbers per word! \n",
    "(A compression ratio of 99.4%)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The word vectors obtained by this process are (to a small extent) random, due to the random initialization of the embedding layers. If you are unhappy with your results, you can repeat the experiment a few times or try to toy around with the hyper-parameters (the smoothing factor of ${X}$, $x_{max}$, $\\alpha$, the number of epochs and the dimensionality of the vector space).\n",
    "</div>\n",
    "\n",
    "Word vectors, however, contain way more information than just word co-occurrence statistics. Hold tight until the next assignment, where we will see how word vectors may be used to infer information spanning entire phrases and sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation (Word Analogies)\n",
    "\n",
    "From the paper:\n",
    "> The word analogy task consists of questions like \"$a$ is to $b$ as is $c$ to $?$\" To correctly answer this question, we must find the word $d$ such that $w_d \\approx w_b - w_a + w_c$ according to the cosine similarity.\n",
    "\n",
    "**Coding 10**: Write your own function that performs the word analogy task.\n",
    "\n",
    "_Hint_: Take a look at the code a few cells back. Most of what you need is already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "torch.return_types.topk(\n",
      "values=tensor([5., 4.]),\n",
      "indices=tensor([4, 3]))\n",
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "fff = torch.arange(1., 6.) +\n",
    "print((fff[4]))\n",
    "print(torch.topk(fff,2))\n",
    "print(fff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(\n",
    "    word_a: str, word_b: str, word_c: str, vocab: Dict[str, int], vectors: FloatTensor, k: int) -> List[str]:\n",
    "    \n",
    "    #get all the names from the voc and put them in a list\n",
    "    bag_of_names = list(vocab.keys())\n",
    "    \n",
    "    #vectors of words from the embedding layers\n",
    "    word_a_ = vectors[vocab[word_a]]\n",
    "    word_b_ = vectors[vocab[word_b]]\n",
    "    word_c_ = vectors[vocab[word_c]]\n",
    "    \n",
    "    #current loc of words from the vocab\n",
    "    current_words = [vocab[word_a], vocab[word_b], vocab[word_c]]\n",
    "    \n",
    "    \n",
    "    #similar word\n",
    "    d = (word_b_ - word_a_ + word_c_).unsqueeze(0)\n",
    "    \n",
    "    #normlize the new d and the vector \n",
    "    d_ = d / torch.norm(d, p=2)  # a/|a|\n",
    "    vectors_ = vectors / torch.norm(vectors, p=2)  # b/|b|\n",
    "\n",
    "    \n",
    "    #make the matrix multiplication ==> the higher value it is, the more similar it is\n",
    "    dot_pro = torch.matmul(d_,vectors_.T)\n",
    "    \n",
    "    #getting the k highest values\n",
    "    highest_six,idx = torch.topk(dot_pro,k,sorted =True)\n",
    "\n",
    "    idx = idx.tolist()\n",
    "    idx= idx[0]\n",
    "    best_words = [bag_of_names[idx[0]]]\n",
    "    \n",
    "    #make sure we dont repeat the same word\n",
    "    for found_word in idx:\n",
    "        if found_word not in current_words:\n",
    "            return bag_of_names[found_word]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher before proceeding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example triplets to test your analogies on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'padma' is to 'parvati' as 'fred' is to ron\n",
      "'avada' is to 'kedavra' as 'expecto' is to easily\n",
      "'dungeon' is to 'slytherin' as 'tower' is to covers\n",
      "'scabbers' is to 'ron' as 'hedwig' is to snape\n",
      "'ron' is to 'molly' as 'draco' is to aged\n",
      "'durmstrang' is to 'viktor' as 'beauxbatons' is to drowning\n",
      "'snape' is to 'potions' as 'trelawney' is to women\n",
      "'harry' is to 'seeker' as 'ron' is to quidditch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "triplets = [(\"padma\", \"parvati\", \"fred\"),\n",
    "            (\"avada\", \"kedavra\", \"expecto\"),\n",
    "            (\"dungeon\", \"slytherin\", \"tower\"),\n",
    "            (\"scabbers\", \"ron\", \"hedwig\"),\n",
    "            (\"ron\", \"molly\", \"draco\"),\n",
    "            (\"durmstrang\", \"viktor\", \"beauxbatons\"),\n",
    "            (\"snape\", \"potions\", \"trelawney\"),\n",
    "            (\"harry\", \"seeker\", \"ron\")\n",
    "           ]\n",
    "\n",
    "for a, b, c in triplets:\n",
    "    print(\"'{}' is to '{}' as '{}' is to {}\".format(a, b, c, analogy(a, b, c, vocab, word_vectors, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some minimal emergent intelligence :) *(hopefully..)*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation 5**: Interpret the results. \n",
    "- Did the model manage to guess the correct answers to the analogies (taking the first word in the output to be the model's \"guess\")? \n",
    "- Are the correct answers present in the top K words? \n",
    "- Do you see any patterns in the cases when the model didn't solve the task correctly? In other words, when the model's guess was wrong, can you suggest why the model guessed what it guessed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "If you are done, you can continue experimenting in order to understand the system's behaviour better. For example: how does training and hyperparameter choice affect the model's performance?\n",
    "Repeat the training using your own hyperparameters (vector space dimensionality, optimizer parameters, the number of training epochs, etc.). \n",
    "\n",
    "During the training loop, print the qualitative benchmarks every few epochs. Do they keep improving? Is there any disadvantage to exhaustively training until convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
